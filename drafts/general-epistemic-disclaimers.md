Thoughts on a general epistemic disclaimer

In private settings people are generally more lax about their epistemic
standards, and are also willing to share more. Is there some way to get people
to share more in public, even if their thoughts are less epistemically careful?
One idea is to slap on a "general epistemic disclaimer" to a subset of public
output, something meaning "this isn't something I would normally make public,
but I am posting it anyway because I want to see more public discourse". A kind
of inverted Crocker's rule, so instead of "Feel free to criticize this
candidly" it is "Please be especially charitable to me".

Some academics already do this when they slap on statements like "please don't
quote from this draft without permission". And ad hoc epistemic disclaimers at
the top of blog posts are becoming more common in the rationalist sphere.

This seems like a bad idea if it is abused so that people use it on almost
anything, and use it as an excuse to e.g. advocate extreme actions.

An analogy with software: Even a skilled programmer cannot write a complicated
program without testing it. Indeed, complicated software must be tested on
different platforms, under different assumptions about user needs, and so
forth, so it is useful to get testers to help test the program. Similarly, an
idea or argument one invents, even after deliberation, is often wrong, so it is
useful to have conversations to help "test out" the idea.

---

Standard disclaimers that can be used on writings? There is also
this more general feeling that I have developed in the past few
years, where it's no longer the exact beliefs that someone
articulates that I care about, but more the thought processes that
this person goes through in trying to reach these conclusions that
I care about and that I find useful. A generally-correct worldview
might be useful for orienting oneself, but when you get down to
the lower-level details, it's more important what you can do with
those details and e.g. that you don't flinch away from certain
implications.

Possible general disclaimers:

-   The things on this page seem reasonable to me, but it hasn't
    been "stress-tested" by others, so it's like a program that
    appears to work but hasn't been tested by a large userbase.
-   This page is just a draft, so I could be saying anything, just
    like someone working privately could be saying anything in
    drafts that never show up in the final product. The only
    difference is that I like to work on things in public, so you
    get to see every step of my work, but that doesn't mean it's
    ready for consumption. Don't even believe that I believe
    everything that is written on this page.

Other points:

-   This is also why the phrase "all things considered" is not
    vacuous; because there are ways to think in a "depth-first"
    way without considering everything, from a "global" stance.
-   Corollary: I like "template questions" or "battery questions"
    that can be applied generally to many tasks, because they
    provide kind of "unit tests" on beliefs. True beliefs tend to
    perform better under these tests, so if something performs
    poorly, that is something against it.
-   People often say to "criticize ideas, not people". But in a
    world where some people criticize people and some criticize
    ideas, it's hard to tell what any one critic is doing.
    Should I be grateful that a critic is "bug testing" my ideas?
    Or should I be wary that as he is doing this, he is also
    downgrading his opinion of me, for having written those ideas?

Another related point: given that we have some person who is interested in
developing an accurate worldview, where on the continuum between (1)
publishing very infrequently only when the quality of work is high and the
person believes they are well-calibrated and well-informed, and (2)
publishing a continuous stream-of-consciousness, would we prefer that this
person to be?

Wei Dai:
<http://lesswrong.com/lw/obf/feature_wish_list_for_lesswrong/djmb>

From [Kaj Sotala's About page](http://kajsotala.fi/about/):

> On my old page, I used to have an extensive page detailing my various
> opinions and other trivia about myself. Over time, my opinions changed,
> but I didn't remember or bother to keep updating the page. Eventually it
> began to reflect me less and less. Even if most of my opinions didn't
> change *that* much, the ones that did made me feel embarrassed about the
> page.
>
> I'm trying to avoid that mistake this time around, so I'll say less
> about myself. In general, please don't presume that I believe in
> anything just because I've said that I believe in it.

---

Thoughts about hedges. Where should we attach our hedges? People
in the rationality sphere have slowly begun attaching "epistemic
status" disclaimers at the top of their blog/Facebook posts. But
is this a good idea, relative to attaching usual hedges at the
relevant locations (e.g. as part of each sentence, or at the
beginning of a paragraph to mark it as "more uncertain", for
instance)? This is not clear to me. Arbital also has confidence
distribution graphs that one can attach to statements, but doing
this for each statement seems excessive.

Another related idea is that people have different ways in which
they like to write, such that it really just *doesn't* make sense
to evaluate them all in the same way. Some people like to think
about a topic for years, having informal conversations with
others, and only after a lot of "battery/stress tests" and so
forth have been applied to an idea do they sit down and take the
time to write it all out. Other people (including myself) like to
"think onto paper", and to write down one *strand of thought* that
seems interesting in the moment, *without making any claims about
its performance on various stress tests*. The idea is to try to
come up with interesting ideas, and hopefully some of them will
turn out to be true and important. The closest analogy my tired
mind can come up with is like trying to
maintain a "portfolio of ideas", where one does not make claims
(at least at the start) that any of them will turn out to be true or
important or significant; rather, one pursues these ideas in the
hopes that *some* of them will turn out to have such properties.
See [Jim Terry on SSC](https://www.quora.com/What-are-peoples-biggest-criticisms-of-Slate-Star-Codex/answer/Jim-Terry-1):

> Is someone a bad blogger if they write good, insightful things, but at
> e.g. a 1:10 ratio to things that are either obvious or wrong? No; that
> actually makes them a really good blogger. But it also opens them to a
> lot of justified criticism. I don't know what SSC's ratio is, but he
> probably is subject to a similar dynamic, which can lead to a situation
> where even readers who learn things from his blog spend most of their
> time on it annoyed at it.

The problem I see, then, is that it's often not easy to
distinguish these two types of writings. Some people, like Holden
Karnofsky circa 2007, have a writing style that ["tended toward
hyperbole rather than careful statement of the strength of my
views"](http://effective-altruism.com/ea/17o/some_thoughts_on_public_discourse/)
in a way that is somewhat obvious for outsiders to figure out. But
in the case of others, it is genuinely difficult to discern exactly how
much they buy into their own current statements. This makes it pretty
difficult to build a model of someone! (It makes it time-consuming,
because you have to get to know them well, have extended conversations,
and so forth.)

Some related ideas here are
["Hedge (linguistics)"](https://en.wikipedia.org/wiki/Hedge_%28linguistics%29),
["Epistemic modality"](https://en.wikipedia.org/wiki/Epistemic_modality).
