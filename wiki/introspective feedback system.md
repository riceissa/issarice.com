---
title: Introspective feedback system
author: Issa Rice
created: 2023-07-16
date: 2023-07-16
---

(terrible name; will try to figure something better out later)

I currently have four software systems I use that all share a similar property:

- a goals spreadsheet
- [[Anki]]
- GnuCash
- alarm clocks on my phone that I use in a particular way (see [[how to wake up at a reasonable hour]])

All four have the property that they are essentially "bookkeeping" in some sense. They help to track things for me, and there's a feedback process where the system tells me to do things but also *I* tell the system things, and the goal is to be in an equilibrium where the system and I *agree*. For instance, the alarm clock tells me it's time to turn off my computer. I can either decide to turn off my computer (I'm agreeing with the system), or I can decide that it's not time to turn off the computer, and adjust the time for that so that *tomorrow* the alarm will be "correct" (I'm disagreeing with the system, or in other words forcing the system to agree with my behavior).

All four systems are, in some sense, a truth-seeking mechanism, where I must introspect to sort out a disagreement.

Qiaochu Yuan once [tweeted](https://twitter.com/QiaochuYuan/status/1481035926948102144) something like: if you don't want to do any of your goals, then introspecting on e.g. why you don't want to do your taxes can itself be a goal, that that introspection is part of what constitutes progress on your taxes. Well, these introspective feedback systems are a sort of generalization of that. The system tells you one thing, but if you believe something different, then part of what it means to use the system -- maybe the whole of it -- is to sort out your disagreement with the system, to figure out your feelings or your memory or your finances or when you should do what.