This is a '''timeline of the Future of Humanity Institute''' (FHI).

==Sample questions==

==Big picture==

{| class="wikitable"
! Time period !! Development summary !! More details
|-
| Before 2005 || This is the period leading up to FHI's existence. Transhumanism, various mailing lists, Bostrom developing his early ideas, etc. ||
|-
| 2005–?? || FHI is founded ||
|-
| 2014–?? || ''Superintelligence'' is published ||
|}

==Visual data==

===Wikipedia pageviews for FHI page===

The following plots pageviews for the {{W|Future of Humanity Institute}} Wikipedia page. The image generated on [https://wikipediaviews.org/displayviewsformultiplemonths.php?page=Future+of+Humanity+Institute&allmonths=allmonths&language=en&drilldown=human Wikipedia Views].

[[File:Future of Humanity Institute Wikipedia pageviews.png|565px]]

===Wikipedia pageviews for Nick Bostrom page===

The following plots pageviews for the {{W|Nick Bostrom}} Wikipedia page. The image is generated on [https://wikipediaviews.org/displayviewsformultiplemonths.php?page=Nick+Bostrom&allmonths=allmonths&language=en&drilldown=human Wikipedia Views].

[[File:Nick Bostrom Wikipedia pageviews.png|400px]]

==Full timeline==

{| class="sortable wikitable"
! Year !! Month and date !! Event type !! Details
|-
| 1973 || {{dts|March 10}} || || {{W|Nick Bostrom}} is born.
|-
| 1998 || {{dts|August 30}} || Website || The domain name for the Anthropic Principle website, <code>anthropic-principle.com</code>, is registered.<ref>{{cite web |url=https://whois.icann.org/en/lookup?name=anthropic-principle.com |title=Showing results for: anthropic-principle.com |publisher=ICANN WHOIS |accessdate=March 11, 2018 |quote=Creation Date: 1998-08-30T04:00:00Z}}</ref> The first Internet Archive snapshot of the website is from January 25, 1999.<ref>{{cite web |url=http://www.anthropic-principle.com:80/ |title=anthropic-principle.com |accessdate=March 11, 2018 |archiveurl=https://web.archive.org/web/19990125093239/http://www.anthropic-principle.com:80/ |archivedate=January 25, 1999 |dead-url=yes}}</ref>
|-
| 1998 || {{dts|August 30}} || Website || The domain name for Nick Bostrom's Future Studies website, <code>future-studies.com</code>, is registered.<ref>{{cite web |url=https://whois.icann.org/en/lookup?name=future-studies.com |title=Showing results for: future-studies.com |publisher=ICANN WHOIS |accessdate=March 15, 2018 |quote=Creation Date: 1998-08-30T04:00:00Z}}</ref> The first Internet Archive snapshot of the website is from October 12, 1999.<ref>{{cite web |url=http://future-studies.com:80/ |title=Future Studies |accessdate=March 15, 2018 |archiveurl=https://web.archive.org/web/19991012022359/http://future-studies.com:80/ |archivedate=October 12, 1999 |dead-url=yes}}</ref>
|-
| 1998 || {{dts|December 14}} || Website || The domain name for Nick Bostrom's analytic philosophy website, <code>analytic.org</code>, is registered.<ref>{{cite web |url=https://whois.icann.org/en/lookup?name=analytic.org |title=Showing results for: ANALYTIC.ORG |publisher=ICANN WHOIS |accessdate=March 15, 2018 |quote=Creation Date: 1998-12-14T05:00:00Z}}</ref> The first Internet Archive snapshot of the website is from November 28, 1999.<ref>{{cite web |url=http://analytic.org:80/ |title=Nick Bostrom's thinking in analytic philosophy |accessdate=March 15, 2018 |archiveurl=https://web.archive.org/web/19991128131608/http://analytic.org:80/ |archivedate=November 28, 1999 |dead-url=yes}}</ref> As of March 2018, the website is not maintained and points to Bostrom's main website, <code>nickbostrom.com</code>.<ref>{{cite web |url=http://analytic.org/ |title=Nick Bostrom's thinking in analytic philosophy |accessdate=March 15, 2018}}</ref>
|-
| 2001 || {{dts|October 31}} || Website || The Simulation Argument website's domain name, <code>simulation-argument.com</code>, is registered.<ref>{{cite web |url=https://whois.icann.org/en/lookup?name=simulation-argument.com |title=Showing results for: simulation-argument.com |publisher=ICANN WHOIS |accessdate=March 11, 2018 |quote=Creation Date: 2001-10-31T08:55:28Z}}</ref> The first Internet Archive snapshot of the website would be on December 5, 2001.<ref>{{cite web |url=https://web.archive.org/web/20010801000000*/simulation-argument.com |title=simulation-argument.com |publisher=Internet Archive |accessdate=March 10, 2018}}</ref> The website hosts information about the [[wikipedia:Simulation hypothesis|simulation hypothesis]], especially as articulated by Bostrom. In the FHI Achievements Report for 2008–2010, the Simulation Argument website is listed under websites maintained by FHI members.<ref name="achievements-report-2008-to-2010">{{cite web |url=http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0019/19900/Achievements_Report_2008-2010.pdf |title=Wayback Machine |accessdate=March 11, 2018 |archiveurl=https://web.archive.org/web/20110516013458/http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0019/19900/Achievements_Report_2008-2010.pdf |archivedate=May 16, 2011 |dead-url=yes}}</ref>
|-
| 2003 || || Publication || {{W|Nick Bostrom}}'s "Astronomical Waste: The Opportunity Cost of Delayed Technological Development" is published in the journal ''{{W|Utilitas}}''.<ref>{{cite web |url=https://nickbostrom.com/astronomical/waste.pdf |title=Astronomical Waste: The Opportunity Cost of Delayed Technological Development |first=Nick |last=Bostrom |accessdate=March 14, 2018}}</ref> This is a featured FHI publication.<ref name="selected-publications-archive">{{cite web |url=https://www.fhi.ox.ac.uk/publications/ |author=Future of Humanity Institute - FHI |title=Selected Publications Archive - Future of Humanity Institute |publisher=Future of Humanity Institute |accessdate=March 14, 2018}}</ref>
|-
| 2005 || {{dts|June 1}} or {{dts|November 29}} || || The Future of Humanity Institute is established.<ref>{{cite web |url=https://www.oxfordmartin.ox.ac.uk/research/programmes/future-humanity/ |publisher=Oxford Martin School |title=About {{!}} Future of Humanity Institute {{!}} Programmes |accessdate=February 7, 2018}}</ref><ref>{{cite web |url=http://fhi.ox.ac.uk/ |title=Future of Humanity Institute |accessdate=February 7, 2018 |archiveurl=https://web.archive.org/web/20051013060521/fhi.ox.ac.uk/ |archivedate=October 13, 2005 |dead-url=yes}}</ref><ref>{{cite web |url=http://www.fhi.ox.ac.uk:80/Papers/FHI%20Newsletter%201%20-%20April%20200611.pdf |title=Wayback Machine |accessdate=February 7, 2018 |archiveurl=https://web.archive.org/web/20060512085807/http://www.fhi.ox.ac.uk:80/Papers/FHI%20Newsletter%201%20-%20April%20200611.pdf |archivedate=May 12, 2006 |dead-url=yes}}</ref>
|-
| 2005 || {{dts|December 18}} || Publication || "How Unlikely is a Doomsday Catastrophe?" by Max Tegmark and Nick Bostrom is published.<ref>{{cite web |url=https://arxiv.org/pdf/astro-ph/0512204v2.pdf |title=How Unlikely is a Doomsday Catastrophe? |first1=Max |last1=Tegmark |first2=Nick |last2=Bostrom |accessdate=March 14, 2018}}</ref> This is a featured FHI publication.<ref name="selected-publications-archive" />
|-
| 2006 || || Publication || "What is a Singleton?" by Nick Bostrom is published in the journal ''{{W|Linguistic and Philosophical Investigations}}''. The paper introduces the idea of a [[wikipedia:Singleton (global governance)|singleton]], a hypothetical "world order in which there is a single decision-making agency at the highest level".<ref>{{cite web |url=https://nickbostrom.com/fut/singleton.html |title=What is a Singleton? |first=Nick |last=Bostrom |accessdate=March 11, 2018}}</ref>
|-
| 2006 || || Staff || Rebecca Roache joins FHI as a research fellow. Her topic of research is ethical issues regrading human enhancement and new technology.<ref name="fhi-report" /><ref>{{cite web |url=http://www.fhi.ox.ac.uk/Papers/R Roache FHI CV.pdf |title=Rebecca Roache |accessdate=March 16, 2018 |archiveurl=https://web.archive.org/web/20070704175820/http://www.fhi.ox.ac.uk/Papers/R%20Roache%20FHI%20CV.pdf |archivedate=July 4, 2007 |dead-url=yes}}</ref>
|-
| 2006 || {{dts|January}} || Staff || Anders Sandberg joins FHI. As of March 2018 he is a Senior Research Fellow at FHI.<ref>{{cite web |url=https://www.linkedin.com/in/anders-sandberg-9215ab145/ |title=Anders Sandberg |publisher=LinkedIn |accessdate=March 15, 2018}}</ref>
|-
| 2006 || {{dts|March 2}} || Website || The ENHANCE project website is created<ref>{{cite web |url=http://www.enhanceproject.org:80/ |author=Anders Sandberg |title=ENHANCE Project Site |accessdate=February 7, 2018 |archiveurl=https://web.archive.org/web/20060406192957/http://www.enhanceproject.org:80/ |archivedate=April 6, 2006 |dead-url=yes}}</ref> by Anders Sandberg.<ref name="fhi-report" />
|-
| 2006 || {{dts|July}} || Publication || "The Reversal Test: Eliminating Status Quo Bias in Applied Ethics" by Nick Bostrom and Toby Ord is published.<ref>{{cite web |url=https://nickbostrom.com/ethics/statusquo.pdf |title=The Reversal Test: Eliminating Status Quo Bias in Applied Ethics |accessdate=March 11, 2018}}</ref> The paper introduces the [[wikipedia:Reversal test|reversal test]] in the context of bioethics of human enhancement. This is a featured FHI publication.<ref name="selected-publications-archive" />
|-
| 2006 || {{dts|July 19}} || Website || The domain name for the existential risk website, <code>existential-risk.org</code>, is registered on this day.<ref>{{cite web |url=https://whois.icann.org/en/lookup?name=existential-risk.org |title=Showing results for: EXISTENTIAL-RISK.ORG |publisher=ICANN WHOIS |accessdate=March 11, 2018 |quote=Creation Date: 2006-07-19T23:23:38Z}}</ref>
|-
| 2006 || {{dts|November 20}} || Website || [[wikipedia:Robin Hanson|Robin Hanson]] starts ''[[wikipedia:Overcoming Bias|Overcoming Bias]]''.<ref>{{cite web |url=http://www.overcomingbias.com/bio |title=Overcoming Bias : Bio |accessdate=June 1, 2017}}</ref> The first post on the blog seems to be from November 20.<ref>{{cite web |url=https://web.archive.org/web/20070119013818/http://robinhanson.typepad.com:80/overcomingbias/2006/11/introduction.html |title=Overcoming Bias: How To Join |accessdate=September 26, 2017}}</ref> On one of the earliest snapshots of the blog, the listed contributors are: Nick Bostrom, Eliezer Yudkowsky, Robin Hanson, Eric Schliesser, Hal Finney, Nicholas Shackel, Mike Huemer, Guy Kahane, Rebecca Roache, Eric Zitzewitz, Peter McCluskey, Justin Wolfers, Erik Angner, David Pennock, Paul Gowder, Chris Hibbert, David Balan, Patri Friedman, Lee Corbin, Anders Sandberg, and Carl Shulman.<ref>{{cite web |url=https://web.archive.org/web/20061207103140/http://overcomingbias.com/ |title=Overcoming Bias |accessdate=September 26, 2017}}</ref> The blog seems to have received support from FHI in the beginning.<ref>{{cite web |url=http://www.fhi.ox.ac.uk:80/updates.html |title=FHI Updates |accessdate=February 7, 2018 |archiveurl=https://web.archive.org/web/20070705000635/http://www.fhi.ox.ac.uk:80/updates.html#blog |archivedate=July 5, 2007 |dead-url=yes}}</ref><ref name="fhi-report">{{cite web |url=http://www.fhi.ox.ac.uk:80/newsletters/Final%20Complete%20FHI%20Report.pdf |title=Wayback Machine |accessdate=February 7, 2018 |archiveurl=https://web.archive.org/web/20090117141825/http://www.fhi.ox.ac.uk:80/newsletters/Final%20Complete%20FHI%20Report.pdf |archivedate=January 17, 2009 |dead-url=yes}}</ref>
|-
| 2006 || {{dts|December}} || Staff || Rafaela Hillerbrand joins FHI as a research fellow for "work on epistemological and ethical problems for decisions under risk and uncertainty". She would remain at FHI until October 2008.<ref>{{cite web |url=https://www.linkedin.com/in/rafaela-hillerbrand-a1759b4/ |title=Rafaela Hillerbrand |publisher=LinkedIn |accessdate=March 15, 2018}}</ref>
|-
| 2006 || {{dts|December 17}} || Outside review || The initial version of the [[wikipedia:Future of Humanity Institute|Wikipedia page for FHI]] is created.<ref>{{cite web |url=https://en.wikipedia.org/w/index.php?title=Future_of_Humanity_Institute&dir=prev&action=history |title=Future of Humanity Institute: Revision history - Wikipedia |accessdate=March 14, 2018 |publisher=[[wikipedia:English Wikipedia|English Wikipedia]]}}</ref>
|-
| 2005–2007 || || || Lighthill Risk Network is created by Peter Taylor of FHI.<ref name="fhi-report" />
|-
| 2007 || {{dts|May}} || Workshop || The Whole Brain Emulation Workshop is hosted by FHI.<ref name="fhi-report" /> The workshop would eventually lead to the publication of "Whole Brain Emulation: A Technical Roadmap" in 2008.<ref name="annual-report-oct-2008-to-sep-2009" />
|-
| 2007 || {{dts|July 18}} || Internal review || The first FHI Achievements Report, covering November 2005 to July 2007, is published.<ref name="fhi-report" />
|-
| 2007 || {{dts|August 24}} || Publication || ''Wittgenstein and His Interpreters: Essays in Memory of Gordon Baker'' is published.<ref>{{cite web |url=https://www.amazon.co.uk/Wittgenstein-His-Interpreters-Essays-Memory/dp/1405129220/ |title=Wittgenstein and His Interpreters: Essays in Memory of Gordon Baker: Amazon.co.uk: Guy Kahane, Edward Kanterian, Oskari Kuusela: 9781405129220: Books |accessdate=February 8, 2018}}</ref><ref name="2010-11-03-books">{{cite web |url=http://www.fhi.ox.ac.uk:80/selected_outputs/recent_books |title=Future of Humanity Institute - Books |accessdate=February 8, 2018 |archiveurl=https://web.archive.org/web/20101103223749/http://www.fhi.ox.ac.uk:80/selected_outputs/recent_books |archivedate=November 3, 2010 |dead-url=yes}}</ref>
|-
| 2007 || {{dts|November}} || Website || ''Practical Ethics in the News'' (at <code>www.practicalethicsnews.com</code>) launches.<ref name="annual-report-oct-2008-to-sep-2009">{{cite web |url=http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0020/19901/FHI_Annual_Report.pdf |title=Wayback Machine |accessdate=March 11, 2018 |archiveurl=https://web.archive.org/web/20120413031223/http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0020/19901/FHI_Annual_Report.pdf |archivedate=April 13, 2012 |dead-url=yes}}</ref> (I think this is the same as ''Practical Ethics'' mentioned below.) At some point the site begins redirecting to http://blog.practicalethics.ox.ac.uk/ but as of March 2018 the site is "temporarily offline for maintenance" (for several years now).
|-
| 2008 || || Website || ''Practical Ethics'', a blog about ethics by FHI's Program on Ethics of the New Biosciences and the Uehiro Centre for Practical Ethics, launches.<ref>{{cite web |url=http://www.fhi.ox.ac.uk:80/updates.html |title=Future of Humanity Institute Updates |accessdate=February 7, 2018 |archiveurl=https://web.archive.org/web/20080915151519/http://www.fhi.ox.ac.uk:80/updates.html |archivedate=September 15, 2008 |dead-url=yes}}</ref>
|-
| 2008 || || Publication || "Whole Brain Emulation: A Technical Roadmap" by Anders Sandberg and Nick Bostrom is published.<ref name="annual-report-oct-2008-to-sep-2009" /> This is a featured FHI publication.<ref name="selected-publications-archive" />
|-
| 2008 || {{dts|January 22}} || Website || The domain name for the Global Catastrophic Risks website, <code>global-catastrophic-risks.com</code>, is registered.<ref>{{cite web |url=https://whois.icann.org/en/lookup?name=global-catastrophic-risks.com |title=Showing results for: global-catastrophic-risks.com |publisher=ICANN WHOIS |accessdate=March 11, 2018 |quote=Creation Date: 2008-01-22T20:47:11Z}}</ref> The first snapshot on the Internet Archive would be on May 5, 2008.<ref>{{cite web |url=https://web.archive.org/web/20080701000000*/global-catastrophic-risks.com |title=global-catastrophic-risks.com |accessdate=March 10, 2018}}</ref>
|-
| 2008 || {{Dts|September 15}} || Publication || ''[[w:Global Catastrophic Risks (book)|Global Catastrophic Risks]]'' is published.<ref>{{cite web |url=https://www.amazon.com/Global-Catastrophic-Risks-Martin-Rees/dp/0198570503 |title=Global Catastrophic Risks: Nick Bostrom, Milan M. Ćirković: 9780198570509: Amazon.com: Books |accessdate=February 8, 2018}}</ref><ref name="2010-11-03-books" />
|-
| 2009 || || Publication || "Probing the Improbable: Methodological Challenges for Risks with Low Probabilities and High Stakes" by Rafaela Hillerbrand, Toby Ord, and Anders Sandberg is published.<ref name="annual-report-oct-2008-to-sep-2009" /> This is a featured FHI publication.<ref name="selected-publications-archive" />
|-
| 2009 || {{dts|January 1}} || Publication || On the group blog (at the time) ''Overcoming Bias'' Nick Bostrom publishes a blog post proposing the Parliamentary Model of dealing with moral uncertainty. The blog post mentions that he is writing a paper on the topic with Toby Ord, but as of March 2018 the paper seems to never have been published. The paper title might be "Fundamental Moral Uncertainty".<ref name="achievements-report-2008-to-2010" /><ref>{{cite web |url=http://www.overcomingbias.com/2009/01/moral-uncertainty-towards-a-solution.html |title=Overcoming Bias : Moral uncertainty – towards a solution? |accessdate=March 10, 2018}}</ref> Despite the idea not being published in full, it is often referenced in discussions.<ref>{{cite web |url=http://lesswrong.com/lw/l55/is_the_potential_astronomical_waste_in_our/ |title=Is the potential astronomical waste in our universe too small to care about? |first=Wei |last=Dai |date=October 21, 2014 |accessdate=March 15, 2018 |publisher=[[wikipedia:LessWrong|LessWrong]]}}</ref><ref>{{cite web |url=https://www.reddit.com/r/science/comments/2hbp21/science_ama_series_im_nick_bostrom_director_of/ckrgodl/ |first=Nick |last=Bostrom |date=September 24, 2014 |publisher=reddit |title=Science AMA Series: I'm Nick Bostrom, Director of the Future of Humanity Institute, and author of "Superintelligence: Paths, Dangers, Strategies", AMA • r/science |accessdate=March 15, 2018}}</ref><ref>{{cite web |url=https://reflectivedisequilibrium.blogspot.com/2014/08/population-ethics-and-inaccessible.html |title=Population ethics and inaccessible populations |accessdate=March 16, 2018 |first=Carl |last=Shulman |date=August 21, 2014 |website=Reflective Disequilibrium |quote=Some approaches, such as Nick Bostrom and Toby Ord's Parliamentary Model, consider what would happen if each normative option had resources to deploy on its own (related to its plausibility or appeal), and look for Pareto-improvements.}}</ref>
|-
| 2009 || {{dts|January 22}} || Publication || ''Human Enhancement'' is published.<ref>{{cite web |url=https://www.amazon.co.uk/Human-Enhancement-Julian-Savulescu/dp/0199299722/ |title=Human Enhancement: Amazon.co.uk: Julian Savulescu, Nick Bostrom: 9780199299720: Books |accessdate=February 8, 2018}}</ref><ref name="2010-11-03-books" /><ref name="annual-report-oct-2008-to-sep-2009" />
|-
| 2009 || {{dts|February}} || Website || ''{{W|LessWrong}}'', the group blog about rationality, launches.<ref>{{cite web |url=https://wiki.lesswrong.com/wiki/FAQ#Where_did_Less_Wrong_come_from.3F |title=FAQ - Lesswrongwiki |accessdate=June 1, 2017 |publisher=[[wikipedia:LessWrong|LessWrong]]}}</ref> The blog is sponsored and endorsed by FHI, although its written contributions seem to be minimal.<ref name="annual-report-oct-2008-to-sep-2009" /><ref name="sotala-siai-vs-fhi" />
|-
| 2009 || {{dts|March 6}} || Social media || The FHI YouTube account, FHIOxford, is created.<ref>{{cite web |url=https://www.youtube.com/user/FHIOxford/about |publisher=YouTube |title=FHIOxford - YouTube |accessdate=March 15, 2018}}</ref>
|-
| 2009 || {{dts|June 19}} || Publication || "Cognitive Enhancement: Methods, Ethics, Regulatory Challenges" by Nick Bostrom and Anders Sandberg is published in the journal ''{{W|Science and Engineering Ethics}}''.<ref>{{cite web |url=https://nickbostrom.com/cognitive.pdf |title=Cognitive Enhancement: Methods, Ethics, Regulatory Challenges |first1=Nick |last1=Bostrom |first2=Anders |last2=Sandberg |year=2009 |accessdate=March 15, 2018}}</ref><ref name="selected-publications-archive" /> By 2011, this would be the "overwhelmingly most cited article" from FHI.<ref name="sotala-siai-vs-fhi" />
|-
| 2009 || {{dts|September}} || Internal review || The FHI Annual Report, covering the period October 1, 2008 to September 30, 2009, is probably published during this month. (The report does not have a date.)<ref name="annual-report-oct-2008-to-sep-2009" />
|-
| 2010 || || Internal review || The FHI Achievements Report, covering the years 2008 to 2010, is probably published during this year. (The report does not have a date so it is unclear when it was published.)<ref name="achievements-report-2008-to-2010" />
|-
| 2010 || {{dts|June 21}} || Publication || ''Anthropic Bias'' by Nick Bostrom is published. The book covers the topic of reasoning under observation selection effects.<ref>{{cite web |url=https://www.amazon.co.uk/Anthropic-Bias-Observation-Selection-Philosophy/dp/0415883946/ |title=Anthropic Bias (Studies in Philosophy): Amazon.co.uk: Nick Bostrom: 9780415883948: Books |accessdate=February 8, 2018}}</ref><ref name="2010-11-03-books" />
|-
| 2010 || {{dts|June}} || Staff || Eric Mandelbaum joins FHI as a postdoctoral research fellow. He would remain at FHI until July 2011.<ref>{{cite web |url=https://static1.squarespace.com/static/54c160eae4b060a8974e59cc/t/59b05ac5f7e0ab27e55d54ee/1504729797699/CV+May+2017.doc |title=Eric Mandelbaum |accessdate=March 16, 2018 |archiveurl=https://web.archive.org/web/20180316012900/https://static1.squarespace.com/static/54c160eae4b060a8974e59cc/t/59b05ac5f7e0ab27e55d54ee/1504729797699/CV+May+2017.doc |archivedate=March 16, 2018 |dead-url=no}}</ref>
|-
| 2011 || {{dts|January 14}}–17 || || The Winter Intelligence Conference, organized by FHI, takes place. The conference brings together experts and students in philosophy, cognitive science, and artificial intelligence for discussions about intelligence.<ref>{{cite web |url=http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0013/20173/Winter_Intelligence_Conference_Report_280111.pdf |title=Winter Intelligence |accessdate=March 15, 2018 |archiveurl=https://web.archive.org/web/20110711082741/http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0013/20173/Winter_Intelligence_Conference_Report_280111.pdf |archivedate=July 11, 2011 |dead-url=yes}}</ref><ref>{{cite web |url=http://www.fhi.ox.ac.uk/archived_events/winter_conference |title=Future of Humanity Institute - Winter Intelligence Conference |accessdate=March 15, 2018 |archiveurl=https://web.archive.org/web/20130116104313/http://www.fhi.ox.ac.uk/archived_events/winter_conference |archivedate=January 16, 2013 |dead-url=yes}}</ref>
|-
| 2011 || {{dts|March 18}} || Publication || ''Enhancing Human Capacities'' is published.<ref>{{cite web |url=https://www.amazon.co.uk/Enhancing-Human-Capacities-Julian-Savulescu/dp/1405195819/ |title=Enhancing Human Capacities: Amazon.co.uk: Julian Savulescu, Ruud ter Meulen, Guy Kahane: 9781405195812: Books |accessdate=February 8, 2018}}</ref><ref>{{cite web |url=http://www.fhi.ox.ac.uk/selected_outputs/recent_books |title=Future of Humanity Institute - Books |accessdate=February 8, 2018 |archiveurl=https://web.archive.org/web/20130116012459/http://www.fhi.ox.ac.uk/selected_outputs/recent_books |archivedate=January 16, 2013 |dead-url=yes}}</ref>
|-
| 2011 || {{dts|June 9}} || Outside review || On a comment thread on ''{{W|LessWrong}}'', a discussion takes place regarding FHI's funding needs, productivity of marginal hires, dispersion of research topics (i.e. lack of focus on existential risks), and other topics related to funding FHI.<ref>{{cite web |url=http://lesswrong.com/lw/634/safety_culture_and_the_marginal_effect_of_a_dollar/4bnx |title=CarlShulman comments on Safety Culture and the Marginal Effect of a Dollar - Less Wrong |accessdate=March 15, 2018 |publisher=[[wikipedia:LessWrong|LessWrong]]}}</ref>
|-
| 2011 || {{dts|September}} || Organization || The Oxford Martin Programme on the Impacts of Future Technology (FutureTech) launches.<ref>{{cite web |url=http://www.futuretech.ox.ac.uk/www.futuretech.ox.ac.uk/index.html |title=Welcome |publisher=Oxford Martin Programme on the Impacts of Future Technology |accessdate=July 26, 2017 |quote=The Oxford Martin Programme on the Impacts of Future Technology, launched in September 2011, is an interdisciplinary horizontal Programme within the Oxford Martin School in collaboration with the Faculty of Philosophy at Oxford University.}}</ref> The Programme is directed by Nick Bostrom and works closely with FHI, among other organizations.
|-
| 2011 || {{dts|September}} || Staff || Stuart Armstrong joins FHI as Research Fellow.<ref>{{cite web |url=https://www.linkedin.com/in/stuart-armstrong-2447743/ |title=Stuart Armstrong |accessdate=March 15, 2018 |publisher=LinkedIn}}</ref>
|-
| 2011 || {{dts|September 25}} || Outside review || Kaj Sotala posts "SIAI vs. FHI achievements, 2008–2010" on ''{{W|LessWrong}}'', comparing the outputs of FHI and the {{W|Machine Intelligence Research Institute}} (which used to be called the Singularity Institute for Artificial Intelligence, abbreviated SIAI).<ref name="sotala-siai-vs-fhi">{{cite web |url=http://lesswrong.com/lw/7sc/siai_vs_fhi_achievements_20082010/ |title=SIAI vs. FHI achievements, 2008-2010 - Less Wrong |accessdate=March 14, 2018 |publisher=[[wikipedia:LessWrong|LessWrong]]}}</ref>
|-
| 2012 || || Staff || Daniel Dewey joins FHI as a Research Fellow.<ref>{{cite web |url=https://www.fhi.ox.ac.uk/wp-content/uploads/Daniel-Dewey.pdf |title=Daniel-Dewey.pdf |accessdate=March 15, 2018}}</ref>
|-
| 2012 || {{dts|June 6}} || Publication || The technical report "Indefinite survival through backup copies" by Anders Sandberg and Stuart Armstrong is published. The paper shows that if an individual entity copies itself so that the number of copies grows logarithmically with time, it will have a nonzero probability of ultimate survival.<ref>{{cite web |url=http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0004/26482/2012-1.pdf |title=Indefinite survival through backup copies |date=June 6, 2012 |first1=Anders |last1=Sandberg |first2=Stuart |last2=Armstrong |accessdate=March 15, 2018 |archiveurl=https://web.archive.org/web/20130116012326/http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0004/26482/2012-1.pdf |archivedate=January 16, 2013 |dead-url=yes}}</ref> This report used to be a featured FHI publication.<ref>{{cite web |url=http://www.fhi.ox.ac.uk/selected_outputs |title=Future of Humanity Institute - Publications |accessdate=March 15, 2018 |archiveurl=https://web.archive.org/web/20130112235857/http://www.fhi.ox.ac.uk/selected_outputs |archivedate=January 12, 2013 |dead-url=yes}}</ref>
|-
| 2012 || {{dts|August 15}} || Website || The first Internet Archive snapshot of the Winter Intelligence Conference website is from this day.<ref>{{cite web |url=http://www.winterintelligence.org:80/ |title=Winter Intelligence Conferences {{!}} The future of artificial general intelligence |accessdate=March 11, 2018 |archiveurl=https://web.archive.org/web/20120815232147/http://www.winterintelligence.org:80/ |archivedate=August 15, 2012 |dead-url=yes}}</ref>
|-
| 2012 || {{dts|September 5}} || Social media || The FHI {{W|Twitter}} account, @FHIOxford, is registered.<ref>{{cite web |url=https://twitter.com/fhioxford?lang=en |title=Future of Humanity Institute (@FHIOxford) |publisher=Twitter |accessdate=March 11, 2018}}</ref>
|-
| 2012 || {{dts|November 16}} || Outside review || John Maxwell IV posts "Room for more funding at the Future of Humanity Institute" on ''{{W|LessWrong}}''.<ref>{{cite web |url=http://lesswrong.com/lw/faa/room_for_more_funding_at_the_future_of_humanity/ |title=Room for more funding at the Future of Humanity Institute - Less Wrong |accessdate=March 14, 2018 |publisher=[[wikipedia:LessWrong|LessWrong]]}}</ref>
|-
| 2012 || {{dts|December 10}}–11 || || FHI hosts the 2012 conference on Impacts and Risks of Artificial General Intelligence. This conference is one of the two conferences that are part of the Winter Intelligence Multi-Conference 2012, which is hosted by FHI.<ref>{{cite web |url=http://www.fhi.ox.ac.uk/archive_news |title=Future of Humanity Institute - News Archive |accessdate=March 11, 2018 |archiveurl=https://web.archive.org/web/20130112235735/http://www.fhi.ox.ac.uk/archive_news |archivedate=January 12, 2013 |dead-url=yes}}</ref><ref>{{cite web |url=http://www.winterintelligence.org/oxford2012/agi-impacts/ |title=AGI Impacts {{!}} Winter Intelligence Conferences |accessdate=March 15, 2018 |archiveurl=https://web.archive.org/web/20121030120754/http://www.winterintelligence.org/oxford2012/agi-impacts/ |archivedate=October 30, 2012 |dead-url=yes}}</ref>
|-
| 2013 || || Staff || Carl Frey and Vincent Müller join FHI as research fellows sometime around this year.<ref>{{cite web |url=http://www.fhi.ox.ac.uk:80/about/staff/ |title=Staff {{!}} Future of Humanity Institute |accessdate=March 16, 2018 |archiveurl=https://web.archive.org/web/20130615192159/http://www.fhi.ox.ac.uk:80/about/staff/ |archivedate=June 15, 2013 |dead-url=yes}}</ref>
|-
| 2013 || {{dts|February}} || Publication || "Existential Risk Prevention as Global Priority" by Nick Bostrom is published in ''{{W|Global Policy}}''.<ref>{{cite web |url=http://www.existential-risk.org/concept.pdf |title=Existential Risk Prevention as Global Priority |first=Nick |last=Bostrom |accessdate=March 14, 2018}}</ref> This is a featured FHI publication.<ref name="selected-publications-archive" />
|-
| 2013 || {{dts|February 25}} || Outside review || "Omens When we peer into the fog of the deep future what do we see – human extinction or a future among the stars?" is published on the digital magazine ''[[wikipedia:Aeon (digital magazine)|Aeon]]''. The piece covers FHI, existential risk, Nick Bostrom, and some of his ideas.<ref>{{cite web |url=https://aeon.co/essays/will-humans-be-around-in-a-billion-years-or-a-trillion |title=Omens When we peer into the fog of the deep future what do we see – human extinction or a future among the stars? |author=Ross Andersen |publisher=Aeon |date=February 25, 2013 |accessdate=March 15, 2018}}</ref><ref>{{cite web |url=http://lesswrong.com/lw/gvb/link_wellwritten_article_on_the_future_of/ |title=[LINK] Well-written article on the Future of Humanity Institute and Existential Risk |date=March 2, 2013 |author=ESRogs |accessdate=March 15, 2018 |publisher=[[wikipedia:LessWrong|LessWrong]]}}</ref>
|-
| 2013 || {{dts|March 12}} || Publication || "Eternity in six hours: intergalactic spreading of intelligent life and sharpening the Fermi paradox" by Stuart Armstrong and Anders Sandberg is published.<ref>{{cite web |url=http://www.fhi.ox.ac.uk/intergalactic-spreading.pdf |title=Eternity in six hours: intergalactic spreading of intelligent life and sharpening the Fermi paradox |first1=Stuart |last1=Armstrong |first2=Anders |last2=Sandberg |accessdate=March 15, 2018 |archiveurl=https://web.archive.org/web/20140409031029/http://www.fhi.ox.ac.uk/intergalactic-spreading.pdf |archivedate=April 9, 2014 |dead-url=yes}}</ref> This paper is a featured FHI publication in 2014.<ref>{{cite web |url=http://www.fhi.ox.ac.uk:80/research/publications/ |title=Publications {{!}} Future of Humanity Institute |accessdate=March 15, 2018 |archiveurl=https://web.archive.org/web/20140523110809/http://www.fhi.ox.ac.uk:80/research/publications/ |archivedate=May 23, 2014 |dead-url=yes}}</ref>
|-
| 2013 || {{dts|May 30}} || || A collaboration between FHI and the insurance company {{W|Amlin}} is announced. The collaboration is for research into systemic risks.<ref>{{cite web |url=https://www.oxfordmartin.ox.ac.uk/news/201305AmlinFHI |publisher=Oxford Martin School |title=FHI & Amlin join forces to understand systemic risk |accessdate=March 15, 2018}}</ref><ref>{{cite web |url=https://www.fhi.ox.ac.uk/research/research-areas/amlin/ |author=Future of Humanity Institute - FHI |title=FHI-Amlin Collaboration - Future of Humanity Institute |publisher=Future of Humanity Institute |accessdate=March 15, 2018}}</ref><ref>{{cite web |url=http://www.fhi.ox.ac.uk:80/research/amlin/ |title=FHI-Amlin Collaboration {{!}} Future of Humanity Institute |accessdate=March 15, 2018 |archiveurl=https://web.archive.org/web/20140523110804/http://www.fhi.ox.ac.uk:80/research/amlin/ |archivedate=May 23, 2014 |dead-url=yes}}</ref>
|-
| 2013 || {{dts|June}} || Staff || Nick Beckstead joins FHI as a Research Fellow. He would remain at FHI until November 2014.<ref>{{cite web |url=https://www.linkedin.com/in/nick-beckstead-7aa54374/ |title=Nick Beckstead |accessdate=March 15, 2018 |publisher=LinkedIn}}</ref>
|-
| 2013 || {{dts|September 17}} || Publication || "The Future of Employment: How Susceptible are Jobs to Computerisation?" by Carl Benedikt Frey and Michael A. Osborne is published.<ref>{{cite web |url=https://www.fhi.ox.ac.uk/wp-content/uploads/The-Future-of-Employment-How-Susceptible-Are-Jobs-to-Computerization.pdf |first1=Carl Benedikt |last1=Frey |first2=Michael A. |last2=Osborne |title=The Future of Employment: How Susceptible are Jobs to Computerisation? |accessdate=March 14, 2018}}</ref> This is a featured FHI publication.<ref name="selected-publications-archive" />
|-
| 2013 || {{dts|December 27}} || Outside review || Chris Hallquist posts "Donating to MIRI vs. FHI vs. CEA vs. CFAR" on ''{{W|LessWrong}}'' about the relative merits of donating to the listed organizations. The discussion thread includes a comment from Seán Ó hÉigeartaigh about the funding needs of FHI.<ref>{{cite web |url=http://lesswrong.com/r/discussion/lw/je9/donating_to_miri_vs_fhi_vs_cea_vs_cfar/ |title=Donating to MIRI vs. FHI vs. CEA vs. CFAR - Less Wrong Discussion |accessdate=March 14, 2018 |publisher=[[wikipedia:LessWrong|LessWrong]]}}</ref>
|-
| 2014 || || || The Global Priorities Project (GPP) runs as a pilot project within the Centre for Effective Altruism. Team members of GPP include Owen Cotton-Barratt and Toby Ord of the Future of Humanity Institute.<ref>{{cite web |url=http://globalprioritiesproject.org/wp-content/uploads/2015/03/GPP-Strategy-Overview-February-2015.pdf |title=Global Priorities Project Strategy Overview |accessdate=March 10, 2018}}</ref> GPP would also eventually become a collaboration between Centre for Effective Altruism and FHI.<ref>{{cite web |url=http://globalprioritiesproject.org/ |publisher=The Global Priorities Project |title=HOME |accessdate=March 10, 2018}}</ref>
|-
| 2014 || || Publication || "Managing existential risk from emerging technologies" by Nick Beckstead and Toby Ord is published in the report "Innovation: Managing Risk, Not Avoiding It. Evidence and Case Studies."<ref>{{cite web |url=https://www.fhi.ox.ac.uk/wp-content/uploads/Managing-existential-risks-from-Emerging-Technologies.pdf |title=Innovation: managing risk, not avoiding it |year=2014 |accessdate=March 14, 2018}}</ref> This is a featured FHI publication.<ref name="selected-publications-archive" />
|-
| 2014 || || Staff || Toby Ord joins FHI as Research Fellow.<ref>{{cite web |url=http://www.amirrorclear.net/files/toby-ord-cv.pdf |title=Toby Ord - CV |accessdate=March 15, 2018}}</ref>
|-
| 2014–2017 || || Staff || Hilary Greaves joins as principal investigator for ''Population Ethics: Theory and Practice'' (organized by FHI).<ref>{{cite web |url=http://users.ox.ac.uk/~mert2255/cv.pdf |title=Curriculum Vitae - Hilary Graves |accessdate=March 16, 2018}}</ref>
|-
| 2014 || {{dts|May 12}} || Social media || FHI researchers {{W|Anders Sandberg}} and Andrew Snyder-Beattie do an AMA ("ask me anything") on {{W|Reddit}}.<ref>{{cite web |url=https://www.reddit.com/r/science/comments/25cnbr/science_ama_series_we_are_researchers_at_the/ |publisher=reddit |title=Science AMA Series: We are researchers at the Future of Humanity Institute at Oxford University, ask us anything! • r/science |accessdate=March 14, 2018}}</ref><ref>{{cite web |url=https://www.fhi.ox.ac.uk/reddit/ |author=Future of Humanity Institute - FHI |title=Future of Humanity Institute answers questions from the public - Future of Humanity Institute |publisher=Future of Humanity Institute |date=May 16, 2014 |accessdate=March 14, 2018}}</ref>
|-
| 2014 || {{dts|July}}–September || Publication || [[wikipedia:Nick Bostrom|Nick Bostrom]]'s book ''[[wikipedia:Superintelligence: Paths, Dangers, Strategies|Superintelligence: Paths, Dangers, Strategies]]'' is published.<ref name="shulman_miri_causal_influences">{{cite web |url=http://effective-altruism.com/ea/ns/my_cause_selection_michael_dickens/50b |title=Carl_Shulman comments on My Cause Selection: Michael Dickens |publisher=Effective Altruism Forum |accessdate=July 6, 2017 |date=September 17, 2015}}</ref> In March 2017, the {{W|Open Philanthropy Project}} considered this book FHI's "most significant output so far and the best strategic analysis of potential risks from advanced AI to date."<ref name="open-phil-grant-march-2017" />
|-
| 2014 || {{dts|September}} || Publication || The policy brief "Unprecedented Technological Risks" by Nick Beckstead et al. is published.<ref>{{cite web |url=https://www.fhi.ox.ac.uk/wp-content/uploads/Unprecedented-Technological-Risks.pdf |title=Unprecedented Technological Risks |first1=Nick |last1=Becktead |first2=Nick |last2=Bostrom |first3=Niel |last3=Bowerman |first4=Owen |last4=Cotton-Barratt |first5=William |last5=MacAskill |first6=Seán Ó |last6=hÉigeartaigh |first7=Toby |last7=Ord |accessdate=March 14, 2018}}</ref> This is a featured FHI publication.<ref name="selected-publications-archive" />
|-
| 2014 || {{dts|September 24}} || Social media || {{W|Nick Bostrom}} does an AMA ("ask me anything") on {{W|Reddit}}.<ref>{{cite web |url=https://www.reddit.com/r/science/comments/2hbp21/science_ama_series_im_nick_bostrom_director_of/ |publisher=reddit |title=Science AMA Series: I'm Nick Bostrom, Director of the Future of Humanity Institute, and author of "Superintelligence: Paths, Dangers, Strategies", AMA • r/science |accessdate=March 14, 2018}}</ref>
|-
| 2014 || {{dts|September 26}} || Outside review || Daniel Dewey (who is a Research Fellow for FHI at the time)<ref>{{cite web |url=https://aiwatch.issarice.com/?person=Daniel+Dewey |date=March 1, 2018 |title=Daniel Dewey |publisher=AI Watch |accessdate=March 14, 2018}}</ref> posts "The Future of Humanity Institute could make use of your money" on ''{{W|LessWrong}}''. The post results in some discussion about donating to FHI in the comments section.
|-
| 2014 || {{Dts|October 28}} || Website || The domain name for the ''Population Ethics: Theory and Practice'' website, <code>populationethics.org</code>, is registered.<ref>{{cite web |url=https://whois.icann.org/en/lookup?name=populationethics.org |title=Showing results for: POPULATIONETHICS.ORG |publisher=ICANN WHOIS |accessdate=March 15, 2018 |quote=Creation Date: 2014-10-28T08:53:08Z}}</ref> The first Internet Archive snapshot of the website would be on December 23, 2014. The "project is organised by the Future of Humanity Institute and supported by the Leverhulme Trust."<ref>{{cite web |url=http://www.populationethics.org:80/ |publisher=Population Ethics: Theory and Practice |title=Welcome |accessdate=March 15, 2018 |archiveurl=https://web.archive.org/web/20141223051017/http://www.populationethics.org:80/ |archivedate=December 23, 2014 |dead-url=yes}}</ref>
|-
| 2015 || || || The Strategic AI Research Center starts some time after this period.<ref>{{cite web |url=https://www.washingtonpost.com/news/in-theory/wp/2015/11/05/qa-philosopher-nick-bostrom-on-superintelligence-human-enhancement-and-existential-risk/?utm_term=.1dd45715e8bd |publisher=[[wikipedia:The Washington Post|The Washington Post]] |title=Opinion {{!}} Q&A: Philosopher Nick Bostrom on superintelligence, human enhancement and existential risk |accessdate=February 8, 2018}}</ref>
|-
| 2015 || || Publication || "Learning the Preferences of Bounded Agents" is published. One of the paper's authors is Owain Evans at FHI.<ref>{{cite web |url=https://www.fhi.ox.ac.uk/wp-content/uploads/nips-workshop-2015-website.pdf |title=Learning the Preferences of Bounded Agents |accessdate=March 10, 2018}}</ref><ref name="larks-december-2016-review" /> This is a featured FHI publication.<ref name="selected-publications-archive" />
|-
| 2015 || || Publication || "Corrigibility" by Soares et al. is published. One of the authors, Stuart Armstrong, is affiliated with FHI. This is a featured FHI publication.<ref name="selected-publications-archive" />
|-
| 2015 || || Staff || Owain Evans joins FHI as a postdoctoral research scientist.<ref>{{cite web |url=https://www.linkedin.com/in/owain-evans-78b210133/ |title=Owain Evans |publisher=LinkedIn |accessdate=March 15, 2018}}</ref>
|-
| 2015 || || Staff || Ben Levinstein joins FHI as a research fellow. He would stay at FHI until 2016.<ref>{{cite web |url=http://www.levinstein.org/cv.html |publisher=Ben Levinstein |title=CV |accessdate=March 15, 2018}}</ref>
|-
| 2015 || || Staff || Simon Beard joins FHI as a research fellow in philosophy, for work on ''Population Ethics: Theory and Practice''. He would remain at FHI until 2016.<ref>{{cite web |url=http://sjbeard.weebly.com/cv.html |publisher=Simon Beard |title=CV |accessdate=March 15, 2018}}</ref>
|-
| 2015 || {{dts|January 2}}–5 || Conference || ''The Future of AI: Opportunities and Challenges'', an AI safety conference, takes place in Puerto Rico. The conference is organized by the Future of Life Institute, but speakers include {{W|Nick Bostrom}}, the director of FHI.<ref>{{cite web |url=https://futureoflife.org/2015/10/12/ai-safety-conference-in-puerto-rico/ |title=AI safety conference in Puerto Rico |publisher=Future of Life Institute |date=October 12, 2015 |accessdate=July 13, 2017}}</ref> Nate Soares (executive director of {{W|Machine Intelligence Research Institute}}) would later call this the "turning point" of when top academics begin to focus on AI risk.<ref>{{cite web |url=https://intelligence.org/2015/07/16/an-astounding-year/ |title=An Astounding Year |publisher=Machine Intelligence Research Institute |author=Nate Soares |date=July 16, 2015 |accessdate=July 13, 2017}}</ref>
|-
| 2015 || {{dts|July 1}} || Financial || The Future of Life Institute's Grant Recommendations for its first round of AI safety grants are publicly announced. The grants would be disbursed on September 1.<ref>{{cite web |url=https://futureoflife.org/grants-timeline/ |title=Grants Timeline - Future of Life Institute |publisher=Future of Life Institute |accessdate=July 13, 2017}}</ref><ref>{{cite web |url=https://futureoflife.org/2015selection/ |title=New International Grants Program Jump-Starts Research to Ensure AI Remains Beneficial: Press release for FLI grant awardees. - Future of Life Institute |publisher=Future of Life Institute |accessdate=July 13, 2017}}</ref><ref>{{cite web |url=https://futureoflife.org/ai-safety-research/ |title=AI Safety Research - Future of Life Institute |publisher=Future of Life Institute |accessdate=July 13, 2017}}</ref> One of the grantees is {{W|Nick Bostrom}}, the director of FHI, who receives a grant of $1,500,000 for the creation of a new research center focused on AI safety.<ref>{{cite web |url=https://futureoflife.org/ai-researcher-nick-bostrom/ |title=AI Researcher Nick Bostrom - Future of Life Institute |publisher=Future of Life Institute |accessdate=March 14, 2018}}</ref> Another grantee is Owain Evans of FHI, who receives a grant of $227,212 for his project on inferring human values.<ref>{{cite web |url=https://futureoflife.org/ai-researcher-owain-evans/ |title=AI Researcher Owain Evans - Future of Life Institute |publisher=Future of Life Institute |accessdate=March 14, 2018}}</ref>
|-
| 2015 || {{dts|July 30}} || Outside review || A post critiquing the lack of intuitive explanation of existential risks on the FHI website (among other places) is posted on ''{{W|LessWrong}}''.<ref>{{cite web |url=http://lesswrong.com/lw/mjy/help_build_a_landing_page_for_existential_risk/ |title=Help Build a Landing Page for Existential Risk? - Less Wrong |accessdate=March 14, 2018 |publisher=[[wikipedia:LessWrong|LessWrong]]}}</ref>
|-
| 2015 || {{dts|September 15}} || Social media || {{W|Anders Sandberg}} does an AMA ("ask me anything") on {{W|Reddit}}.<ref>{{cite web |url=https://www.reddit.com/r/Futurology/comments/3l1jqs/i_am_a_researcher_at_the_future_of_humanity/ |publisher=reddit |title=I am a researcher at the Future of Humanity Institute in Oxford, working on future studies, human enhancement, global catastrophic risks, reasoning under uncertainty and everything else. Ask me anything! • r/Futurology |accessdate=March 14, 2018}}</ref>
|-
| 2015 || {{dts|October}} || Publication || "Moral Trade" by Toby Ord is published in the journal ''[[wikipedia:Ethics (journal)|Ethics]]''.<ref>{{cite web |url=http://www.amirrorclear.net/files/moral-trade.pdf |title=Moral Trade |first=Toby |last=Ord |journal=Ethics |year=2015 |accessdate=March 14, 2018}}</ref> This is a featured FHI publication.<ref name="selected-publications-archive" />
|-
| 2015 || {{dts|November 23}} || Outside review || A ''{{W|The New Yorker}}'' piece featuring Nick Bostrom and FHI is published.<ref>{{cite web |url=https://www.newyorker.com/magazine/2015/11/23/doomsday-invention-artificial-intelligence-nick-bostrom |title=The Doomsday Invention: Will artificial intelligence bring us utopia or destruction? |publisher=The New Yorker |first=Raffi |last=Khatchadourian |date=November 23, 2015 |accessdate=March 15, 2018}}</ref>
|-
| 2016 || || Publication || Stuart Armstrong's paper "Off-policy Monte Carlo agents with variable behaviour policies" is published.<ref>{{cite web |url=https://www.fhi.ox.ac.uk/wp-content/uploads/monte_carlo_arXiv.pdf |title=Off-policy Monte Carlo agents with variable behaviour policies |first=Stuart |last=Armstrong |accessdate=March 10, 2018}}</ref><ref name="larks-december-2016-review" /> This is a featured FHI publication.<ref name="selected-publications-archive" />
|-
| 2016 || || Publication || "Learning the Preferences of Ignorant, Inconsistent Agents" is published. One of the paper's authors is Owain Evans at FHI.<ref>{{cite web |url=https://stuhlmueller.org/papers/preferences-aaai2016.pdf |title=Learning the Preferences of Ignorant, Inconsistent Agents |accessdate=March 10, 2018}}</ref><ref name="larks-december-2016-review" /> This is a featured FHI publication.<ref name="selected-publications-archive" />
|-
| 2016 || || || The Global Politics of AI Research Group is established by Carrick Flynn and Allan Dafoe (both of whom are affiliated with FHI). The group "consists of eleven research members more than thirty volunteers" and "has the mission of helping researchers and political actors to adopt the best possible strategy around the development of AI."<ref name="annual-review-2016" /> (It's not clear where the group is based or if it even meets physically.)
|-
| 2016 || || Publication || "Thompson Sampling is Asymptotically Optimal in General Environments" by Leike et al. is published.<ref>{{cite web |url=http://auai.org/uai2016/proceedings/papers/20.pdf |title=Thompson Sampling is Asymptotically Optimal in General Environments |first1=Jan |last1=Leike |first2=Tor |last2=Lattimore |first3=Laurent |last3=Orseau |first4=Marcus |last4=Hutter |accessdate=March 14, 2018}}</ref> This is a featured FHI publication.<ref name="selected-publications-archive" />
|-
| 2016 || {{dts|January 26}} || Publication || "The Unilateralist's Curse and the Case for a Principle of Conformity" by Nick Bostrom, Thomas Douglas, and Anders Sandberg is published in the journal ''[[wikipedia:Social Epistemology (journal)|Social Epistemology]]''.<ref>{{cite web |url=https://www.tandfonline.com/doi/full/10.1080/02691728.2015.1108373 |title=The Unilateralist's Curse and the Case for a Principle of Conformity |publisher=Taylor & Francis |accessdate=March 14, 2018}}</ref> This is a featured FHI publication.<ref name="selected-publications-archive" />
|-
| 2016 || {{dts|February 8}}–9 || Workshop || The Global Priorities Project (a collaboration between FHI and the Centre for Effective Altruism) hosts a policy workshop on existential risk. Attendees included "twenty leading academics and policy-makers from the UK, USA, Germany, Finland, and Sweden".<ref>{{cite web |url=https://www.fhi.ox.ac.uk/workshop-hosted-on-existential-risk/ |author=Future of Humanity Institute - FHI |title=Policy workshop hosted on existential risk - Future of Humanity Institute |publisher=Future of Humanity Institute |date=October 25, 2016 |accessdate=March 13, 2018}}</ref><ref name="annual-review-2016" />
|-
| 2016 || {{dts|May}} || Publication || The Global Priorities Project (associated with FHI) releases the Global Catastrophic Report 2016.<ref name="newsletter-summer-2016">{{cite web |url=https://www.fhi.ox.ac.uk/quarterly-newsletter-july-2016/ |author=Future of Humanity Institute - FHI |title=Quarterly Update Summer 2016 - Future of Humanity Institute |publisher=Future of Humanity Institute |date=July 31, 2017 |accessdate=March 13, 2018}}</ref>
|-
| 2016 || {{dts|May}} || Workshop || FHI hosts a week-long workshop in Oxford called "The Control Problem in AI", attended by ten members of {{W|Machine Intelligence Research Institute}}.<ref name="annual-review-2016" />
|-
| 2016 || {{dts|May 27}}{{snd}}{{dts|June 17}} || Workshop || The Colloquium Series on Robust and Beneficial AI (CSRBAI), co-hosted by the {{w|Machine Intelligence Research Institute}} and FHI, takes place. The program brings "together a variety of academics and professionals to address the technical challenges associated with AI robustness and reliability, with a goal of facilitating conversations between people interested in a number of different approaches." At the program, Jan Leike and Stuart Armstrong of FHI each give a talk.<ref>{{cite web |url=https://intelligence.org/colloquium-series/ |title=Colloquium Series on Robust and Beneficial AI - Machine Intelligence Research Institute |publisher=[[wikipedia:Machine Intelligence Research Institute|Machine Intelligence Research Institute]] |accessdate=March 13, 2018}}</ref>
|-
| 2016 || {{Dts|June}} (approximate) || || FHI recruits {{W|William MacAskill}} and Hilary Greaves to start a new "Programme on the Philosophical Foundations of Effective Altruism" as a collaboration between FHI and the Centre for Effective Altruism.<ref name="newsletter-summer-2016" /> (It seems like this became the Global Priorities Institute.)
|-
| 2016 || {{dts|June}} || Publication || ''[[wikipedia:The Age of Em|The Age of Em: Work, Love and Life When Robots Rule the Earth]]'', a book about the implications of whole brain emulation by FHI research associate {{W|Robin Hanson}}, is published.<ref>{{cite web |url=http://ageofem.com/ |title=The Age of Em, A Book |accessdate=March 13, 2018}}</ref> In October, FHI and Hanson would organize a workshop about the book.<ref name="annual-review-2016" />
|-
| 2016 || {{dts|June 1}} || Publication || The paper "Safely interruptible agents" is announced on the {{W|Machine Intelligence Research Institute}} blog. The paper is a collaboration between {{W|Google DeepMind}} and FHI, and one of the paper's authors is Stuart Armstrong of FHI.<ref>{{cite web |url=https://intelligence.org/2016/06/01/new-paper-safely-interruptible-agents/ |title=New paper: "Safely interruptible agents" - Machine Intelligence Research Institute |publisher=[[wikipedia:Machine Intelligence Research Institute|Machine Intelligence Research Institute]] |date=September 12, 2016 |first=Rob |last=Bensinger |accessdate=March 10, 2018}}</ref><ref name="larks-december-2016-review">{{cite web |url=http://effective-altruism.com/ea/14w/2017_ai_risk_literature_review_and_charity/ |title=2017 AI Risk Literature Review and Charity Comparison - Effective Altruism Forum |accessdate=March 10, 2018}}</ref> The paper is also presented at the Conference on Uncertainty in Artificial Intelligence (UAI).<ref name="newsletter-summer-2016" /><ref>{{cite web |url=http://lesswrong.com/lw/noj/google_deepmind_and_fhi_collaborate_to_present/ |title=Google Deepmind and FHI collaborate to present research at UAI 2016 |author=Stuart Armstrong |accessdate=March 14, 2018 |publisher=[[wikipedia:LessWrong|LessWrong]]}}</ref> This is a featured FHI publication.<ref name="selected-publications-archive" />
|-
| 2016 || {{dts|August}} || Staff || Piers Millett joins FHI as Senior Research Fellow.<ref>{{cite web |url=https://www.linkedin.com/in/pdmillett/ |title=Piers Millett |publisher=LinkedIn |accessdate=March 15, 2018}}</ref>
|-
| 2016 || {{dts|September}} || Financial || The {{W|Open Philanthropy Project}} recommends (to Good Ventures?) a grant of $115,652 to FHI to support the hiring of Piers Millett, who will work on biosecurity and pandemic preparedness.<ref>{{cite web |url=https://www.openphilanthropy.org/focus/global-catastrophic-risks/biosecurity/future-humanity-institute-biosecurity-and-pandemic-preparedness |publisher=Open Philanthropy Project |title=Future of Humanity Institute — Biosecurity and Pandemic Preparedness |date=December 15, 2017 |accessdate=March 10, 2018}}</ref>
|-
| 2016 || {{dts|September}} (approximate) || Financial || FHI receives a funding offer from Luke Ding to fund Hilary Greaves for four years starting mid-2017 (in case a proposed new institute is unable to raise academic funds for her) and William MacAskill's full salary for five years.<ref>{{cite web |url=https://www.fhi.ox.ac.uk/q3-newsletter/ |author=Future of Humanity Institute |title=Quarterly Update Autumn 2016 |publisher=Future of Humanity Institute |date=July 31, 2017 |accessdate=March 13, 2018}}</ref>
|-
| 2016 || {{dts|September 16}} || Publication || Jan Leike's paper "Exploration Potential" is first uploaded to the arXiv.<ref>{{cite web |url=https://arxiv.org/abs/1609.04994 |title=[1609.04994] Exploration Potential |accessdate=March 10, 2018}}</ref><ref name="larks-december-2016-review" /><ref name="annual-review-2016" />
|-
| 2016 || {{dts|September 22}} || || FHI's page on its collaboration with Google DeepMind is published. However it is unclear when the actual collaboration began.<ref>{{cite web |url=https://www.fhi.ox.ac.uk/deepmind-collaboration/ |author=Future of Humanity Institute - FHI |title=DeepMind collaboration - Future of Humanity Institute |publisher=Future of Humanity Institute |date=March 8, 2017 |accessdate=March 13, 2018}}</ref>
|-
| 2016 || {{dts|November}} || Workshop || The biotech horizon scanning workshop, co-hosted by the Centre for the Study of Existential Risk and FHI, takes place. The workshop and the overall "biological engineering horizon scanning" process is intended to lead up to "a peer-reviewed publication highlighting 15–20 developments of greatest likely impact."<ref name="annual-review-2016" /><ref>{{cite web |url=https://www.fhi.ox.ac.uk/biotech-horizon-scanning-workshop/ |author=Future of Humanity Institute - FHI |title=Biotech horizon scanning workshop - Future of Humanity Institute |publisher=Future of Humanity Institute |date=December 12, 2016 |accessdate=March 13, 2018}}</ref>
|-
| 2016 || {{dts|December}} || Workshop || FHI hosts a workshop on "AI Safety and Blockchain". Attendees include Nick Bostrom, Vitalik Buterin, {{W|Jaan Tallinn}}, {{W|Wei Dai}}, Gwern Branwen, and Allan Dafoe. "The workshop explored the potential technical overlap between AI Safety and blockchain technologies and the possibilities for using blockchain, crypto-economics, and cryptocurrencies to facilitate greater global coordination."<ref>{{cite web |url=https://www.fhi.ox.ac.uk/fhi-holds-workshop-on-ai-safety-and-blockchain/ |author=Future of Humanity Institute - FHI |title=FHI holds workshop on AI safety and blockchain - Future of Humanity Institute |publisher=Future of Humanity Institute |date=January 19, 2017 |accessdate=March 13, 2018}}</ref><ref name="annual-review-2016" /> It is unclear whether any output resulted from this workshop.
|-
| 2017 || || Publication || Slides for an upcoming paper by FHI researchers Anders Sandberg, Eric Drexler, and Toby Ord, "Dissolving the Fermi Paradox", are posted.<ref>{{cite web |url=http://marginalrevolution.com/marginalrevolution/2017/07/fermi-paradox-resolved.html |title=Has the Fermi paradox been resolved? - Marginal REVOLUTION |publisher=Marginal REVOLUTION |date=July 3, 2017 |accessdate=March 13, 2018}}</ref><ref>{{cite web |url=https://www.gwern.net/newsletter/2017/09 |author=gwern |date=August 16, 2017 |title=September 2017 news - Gwern.net |accessdate=March 13, 2018}}</ref>
|-
| 2017 || || Publication || The report "Existential Risk: Diplomacy and Governance" is published. "This work began at the Global Priorities Project, whose policy work has now joined FHI."<ref name="newsletter-spring-2017" /> The report gives an overview of existential risks and presents three recommendations for ways to reduce existential risks (chosen out of more then 100 proposals): (1) developing governance of geoengineering research; (2) establishing scenario plans and exercises for severe engineered pandemics at the international level; and (3) building international attention and support for existential risk reduction.<ref>{{cite web |url=https://www.fhi.ox.ac.uk/wp-content/uploads/Existential-Risks-2017-01-23.pdf |title=Existential Risk: Diplomacy and Governance |year=2017 |first1=Sebastian |last1=Farquhar |first2=John |last2=Halstead |first3=Owen |last3=Cotton-Barratt |first4=Stefan |last4=Schubert |first5=Haydn |last5=Belfield |first6=Andrew |last6=Snyder-Beattie |publisher=Global Priorities Project |accessdate=March 14, 2018}}</ref>
|-
| 2017 || {{dts|January 15}} || Publication || "Agent-Agnostic Human-in-the-Loop Reinforcement Learning" is uploaded to the arXiv.<ref>{{cite web |url=https://arxiv.org/abs/1701.04079v1 |title=[1701.04079v1] Agent-Agnostic Human-in-the-Loop Reinforcement Learning |accessdate=March 14, 2018}}</ref><ref name="newsletter-spring-2017" />
|-
| 2017 || {{dts|January 25}} || Publication || The FHI Annual Review 2016 is published.<ref name="annual-review-2016">{{cite web |url=https://www.fhi.ox.ac.uk/fhi-annual-review-2016/ |author=Future of Humanity Institute - FHI |title=FHI Annual Review 2016 - Future of Humanity Institute |publisher=Future of Humanity Institute |date=July 31, 2017 |accessdate=March 13, 2018}}</ref>
|-
| 2017 || {{dts|February 9}} || Publication || Nick Bostrom's paper "Strategic Implications of Openness in AI Development" is published in the journal ''{{W|Global Policy}}''.<ref>{{cite web |url=http://onlinelibrary.wiley.com/doi/10.1111/1758-5899.12403/abstract |title=Strategic Implications of Openness in AI Development |accessdate=March 10, 2018}}</ref><ref name="larks-december-2016-review" /><ref name="newsletter-spring-2017">{{cite web |url=https://www.fhi.ox.ac.uk/quarterly-update-spring-2017/ |author=Future of Humanity Institute - FHI |title=Quarterly Update Spring 2017 - Future of Humanity Institute |publisher=Future of Humanity Institute |date=July 31, 2017 |accessdate=March 14, 2018}}</ref> The paper "covers a breadth of areas including long-term AI development, singleton versus multipolar scenarios, race dynamics, responsible AI development, and identification of possible failure modes."<ref name="annual-review-2016" /> This is a featured FHI publication.<ref name="selected-publications-archive" />
|-
| 2017 || {{dts|March}} || Financial || The {{W|Open Philanthropy Project}} recommends (to Good Ventures?) a grant of $1,995,425 to FHI for general support.<ref name="open-phil-grant-march-2017">{{cite web |url=https://www.openphilanthropy.org/focus/global-catastrophic-risks/potential-risks-advanced-artificial-intelligence/future-humanity-institute-general-support |publisher=Open Philanthropy Project |title=Future of Humanity Institute — General Support |date=December 15, 2017 |accessdate=March 10, 2018}}</ref>
|-
| 2017 || {{dts|April 26}} || Publication || The online book ''Modeling Agents with Probabilistic Programs'' by Owain Evans (FHI research fellow), Andreas Stuhlmüller, John Salvatier (FHI intern), and Daniel Filan (FHI intern) is published. The book is available at [https://agentmodels.org/ <code>https://agentmodels.org/</code>].<ref>{{cite web |url=https://agentmodels.org/ |title=Modeling Agents with Probabilistic Programs |accessdate=March 13, 2018}}</ref><ref>{{cite web |url=https://www.fhi.ox.ac.uk/new-interactive-tutorial-planning-reinforcement-learning/ |author=Future of Humanity Institute - FHI |title=New Interactive Tutorial: Modeling Agents with Probabilistic Programs - Future of Humanity Institute |publisher=Future of Humanity Institute |date=April 26, 2017 |accessdate=March 13, 2018}}</ref>
|-
| 2017 || {{dts|April 27}} || Publication || "That is not dead which can eternal lie: the aestivation hypothesis for resolving Fermi's paradox" is uploaded to the arXiv.<ref>{{cite web |url=https://arxiv.org/abs/1705.03394 |title=[1705.03394] That is not dead which can eternal lie: the aestivation hypothesis for resolving Fermi's paradox |accessdate=March 10, 2018}}</ref><ref name="larks-december-2017-review" /><ref name="newsletter-summer-2017">{{cite web |url=https://www.fhi.ox.ac.uk/quarterly-update-summer-2017/ |author=Future of Humanity Institute - FHI |title=FHI Quarterly Update Summer 2017 |publisher=Future of Humanity Institute |date=July 31, 2017 |accessdate=March 14, 2018}}</ref>
|-
| 2017 || {{dts|May 24}} || Publication || "When Will AI Exceed Human Performance? Evidence from AI Experts" is published on the {{w|arXiv}}. Three of the authors of this paper are affiliated with FHI: Katja Grace, Allan Dafoe, and Owain Evans.<ref>{{cite web |url=https://arxiv.org/abs/1705.08807 |title=[1705.08807] When Will AI Exceed Human Performance? Evidence from AI Experts |accessdate=July 13, 2017}}</ref>
|-
| 2017 || {{dts|July}} || Financial || The {{W|Open Philanthropy Project}} recommends (to Good Ventures?) a grant of $299,320 to Yale University to support "to support research on the global politics of advanced artificial intelligence". The work will be led by Allan Dafoe, who will conduct part of the work at FHI.<ref>{{cite web |url=https://www.openphilanthropy.org/focus/global-catastrophic-risks/potential-risks-advanced-artificial-intelligence/yale-university-global-politics-of-ai-dafoe |publisher=Open Philanthropy Project |title=Yale University — Research on the Global Politics of AI |date=December 15, 2017 |accessdate=March 11, 2018}}</ref>
|-
| 2017 || {{Dts|July 17}} || Publication || "Trial without Error: Towards Safe Reinforcement Learning via Human Intervention" is uploaded to the arXiv.<ref>{{cite web |url=https://arxiv.org/abs/1707.05173 |title=[1707.05173] Trial without Error: Towards Safe Reinforcement Learning via Human Intervention |accessdate=March 10, 2018}}</ref><ref name="larks-december-2017-review">{{cite web |url=http://effective-altruism.com/ea/1iu/2018_ai_safety_literature_review_and_charity/ |title=2018 AI Safety Literature Review and Charity Comparison |author=Larks |publisher=Effective Altruism Forum |accessdate=March 10, 2018}}</ref>
|-
| 2017 || {{dts|August 25}} || Publication || FHI announces three new forthcoming papers in the latest issue of ''Health Security''.<ref>{{cite web |url=https://www.fhi.ox.ac.uk/fhi-publishes-three-new-biosecurity-papers-health-security/ |author=Future of Humanity Institute - FHI |title=FHI publishes three new biosecurity papers in 'Health Security' - Future of Humanity Institute |publisher=Future of Humanity Institute |date=August 25, 2017 |accessdate=March 14, 2018}}</ref><ref name="newsletter-autumn-2017">{{cite web |url=https://www.fhi.ox.ac.uk/quarterly-update-autumn-2017/ |author=Future of Humanity Institute - FHI |title=Quarterly Update Autumn 2017 - Future of Humanity Institute |publisher=Future of Humanity Institute |date=October 10, 2017 |accessdate=March 14, 2018}}</ref>
|-
| 2017 || {{dts|September 27}} || || Carrick Flynn, a research project manager at FHI,<ref>{{cite web |url=https://www.fhi.ox.ac.uk/team/carrick-flynn/ |author=Future of Humanity Institute - FHI |title=Carrick Flynn - Future of Humanity Institute |publisher=Future of Humanity Institute |accessdate=March 15, 2018}}</ref> posts his thoughts on AI policy and strategy on the Effective Altruism Forum. Although he only writes in a personal capacity in the post, it is informed by his experience at FHI.<ref>{{cite web |url=http://effective-altruism.com/ea/1fa/personal_thoughts_on_careers_in_ai_policy_and/ |title=Personal thoughts on careers in AI policy and strategy |first=Carrick |last=Flynn |publisher=Effective Altruism Forum |accessdate=March 15, 2018}}</ref>
|-
| 2017 || {{dts|September 29}} || Financial || Effective Altruism Grants fall 2017 recipients are announced. One of the recipients is Gregory Lewis, who will use the grant for "Research into biological risk mitigation with the Future of Humanity Institute." The grant amount for Lewis is £15,000 (about $20,000).<ref>{{cite web |url=https://docs.google.com/spreadsheets/d/1iBy–zMyIiTgybYRUQZIm11WKGQZcixaCmIaysRmGvk/edit#gid=0 |title=EA Grants Fall 2017 Recipients |publisher=Google Docs |accessdate=March 11, 2018}}</ref>
|-
| 2017 || {{Dts|October}}–December || || FHI launches its Governance of AI Program, co-directed by Nick Bostrom and Allan Dafoe.<ref name="newsletter-winter-2017">{{cite web |url=https://www.fhi.ox.ac.uk/quarterly-update-winter-2017/ |author=Future of Humanity Institute - FHI |title=Quarterly Update Winter 2017 - Future of Humanity Institute |publisher=Future of Humanity Institute |date=January 19, 2018 |accessdate=March 14, 2018}}</ref>
|-
| 2018 || {{dts|February 20}} || Publication || The report "The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation" is published. The report forecasts malicious use of artificial intelligence in the short term and makes recommendations on how to mitigate these risks from AI. The report is authored by individuals at Future of Humanity Institute, Centre for the Study of Existential Risk, OpenAI, Electronic Frontier Foundation, Center for a New American Security, and other institutions.<ref>{{cite web |url=https://arxiv.org/abs/1802.07228 |title=[1802.07228] The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation |accessdate=February 24, 2018}}</ref><ref>{{cite web |url=https://blog.openai.com/preparing-for-malicious-uses-of-ai/ |publisher=OpenAI Blog |title=Preparing for Malicious Uses of AI |date=February 21, 2018 |accessdate=February 24, 2018}}</ref><ref>{{cite web |url=https://maliciousaireport.com/ |author=Malicious AI Report |publisher=Malicious AI Report |title=The Malicious Use of Artificial Intelligence |accessdate=February 24, 2018}}</ref>
|}

==Meta information on the timeline==

===How the timeline was built===

The initial version of the timeline was written by [[User:Issa|Issa Rice]].

See the [https://github.com/riceissa/issarice.com/commits/master/external/timelines.issarice.com/Timeline_of_Future_of_Humanity_Institute.mediawiki commit history on GitHub] for a more detailed revision history.

{{funding info}} is available.

===What the timeline is still missing===

* "Sean is currently working overtime to cover a missing administrative staff member, but he plans to release a new achievement report (see sidebar on this page for past achievement reports) sometime in the next few months." [http://lesswrong.com/lw/faa/room_for_more_funding_at_the_future_of_humanity/] However, the last "Achievements Report" I can find ends in 2010.
* i'm curious what output is associated with "Applied epistemology" research agenda https://web.archive.org/web/20130116011525/http://www.fhi.ox.ac.uk/research/rationality_and_wisdom
* when did FHI start doing more ML-based stuff? was it after it hired owain evans?
* https://web.archive.org/web/20110908095411/http://www.fhi.ox.ac.uk/__data/assets/pdf_file/0003/19902/Final_Complete_FHI_Report.pdf (see pages 76-77)

===Timeline update strategy===

* FHI posts new quarterly updates here: https://www.fhi.ox.ac.uk/reporting/

==See also==

* [[Timeline of AI safety]]
* [[Timeline of Machine Intelligence Research Institute]]
* [[Timeline of the rationality community]]

==External links==

* {{W|Future of Humanity Institute}} (Wikipedia)
* [https://wiki.lesswrong.com/wiki/Future_of_Humanity_Institute LessWrong Wiki]
* [https://donations.vipulnaik.com/donee.php?donee=Future+of+Humanity+Institute Donations List Website (donee)]
* [https://aiwatch.issarice.com/?organization=Future+of+Humanity+Institute AI Watch]

==References==

{{Reflist|30em}}
