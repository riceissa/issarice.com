This is a '''timeline of Machine Intelligence Research Institute'''. [[wikipedia:Machine Intelligence Research Institute|Machine Intelligence Research Institute]] (MIRI) is a nonprofit organization that does work related to AI safety.

==Sample questions==

This is an experimental section that provides some sample questions for readers, similar to reading questions that might come with a book. Some readers of this timeline might come to the page aimlessly and might not have a good idea of what they want to get out of the page. Having some "interesting" questions can help in reading the page with more purpose and in getting a sense of why the timeline is an important tool to have.

The following are some interesting questions that can be answered by reading this timeline:

* Which Singularity Summits did MIRI host, and when did they happen? (Sort by the "Event type" column and look at the rows labeled "Conference".)
* What was MIRI up to for the first ten years of its existence (before Luke Muehlhauser joined, before Holden Karnofsky wrote his critique of the organization)? (Scan the years 2000–2009.)
* How has MIRI's explicit mission changed over the years? (Sort by the "Event type" column and look at the rows labeled "Mission".)

The following are some interesting questions that are difficult or impossible to answer just by reading the current version of this timeline, but might be possible to answer using a future version of this timeline:

* When did some big donations to MIRI take place (for instance, the one by Peter Thiel)?
* Has MIRI "done more things" between 2010–2013 or between 2014–2017?

==Big picture==

{| class="wikitable"
! Time period !! Development summary !! More details
|-
| 1998–2002 || Various publications related to creating a superhuman AI || Eliezer Yudkowsky writes various documents about designing a superhuman AI during this period, including "Coding a Transhuman AI", "The Plan to Singularity", and "Creating Friendly AI". The Flare Programming Language project launches to aid the creation of a superhuman AI.
|-
| 2004–2009 || Tyler Emerson's tenure as executive director ||
|-
| 2006–2009 || Modern rationalist community forms || ''Overcoming Bias'' is created, LessWrong is created, Eliezer Yudkowsky writes the Sequences, and so on.
|-
| 2006–2012 || The Singularity Summits take place annually || After the summit in 2012, the organization renames itself from "Singularity Institute for Artificial Intelligence" to the current "Machine Intelligence Research Institute".
|-
| 2009–2012 || Michael Vassar's tenure as president ||
|-
| 2011–2015 || Luke Muehlhauser's tenure as executive director ||
|-
| 2013–present || Change of focus || MIRI changes focus to put less effort into public outreach and shift its research to Friendly AI math research.
|-
| 2015–present || Nate Soares's tenure as executive director ||
|}

==Full timeline==

{| class="sortable wikitable"
! Year !! Month and date !! Event type !! Details
|-
| 1979 || {{dts|September 11}} || || Eliezer Yudkowsky is born.<ref>{{cite web |url=http://sysopmind.com/eliezer.html |archiveurl=https://web.archive.org/web/20010205221413/http://sysopmind.com/eliezer.html |archivedate=February 5, 2001 |author=Eliezer S. Yudkowsky |title=Eliezer, the person |date=August 31, 2000}}</ref>
|-
| 1996 || {{dts|November 18}} || || Eliezer Yudkowsky writes the first version of "Staring into the Singularity".<ref>{{cite web |url=http://yudkowsky.net/obsolete/singularity.html |title=Yudkowsky - Staring into the Singularity 1.2.5 |accessdate=June 1, 2017}}</ref>
|-
| 1998 || || Publication || The initial version of "Coding a Transhuman AI" (CaTAI) is published.<ref>{{cite web |url=https://web.archive.org/web/20010202165700/http://sysopmind.com:80/AI_design.temp.html |author=Eliezer S. Yudkowsky |title=Coding a Transhuman AI |accessdate=July 5, 2017}}</ref>
|-
| 1999 || {{dts|March 11}} || || The Singularitarian mailing list is launched. The mailing list page notes that although hosted on MIRI's website, the mailing list "should be considered as being controlled by the individual Eliezer Yudkowsky".<ref>{{cite web |url=https://web.archive.org/web/20010127202200/http://singinst.org:80/lists/sing.html |author=Eliezer S. Yudkowsky |title=Singularitarian mailing list |accessdate=July 5, 2017 |quote=The "Singularitarian" mailing list was first launched on Sunday, March 11th, 1999, to assist in the common goal of reaching the Singularity. It will do so by pooling the resources of time, brains, influence, and money available to Singularitarians; by enabling us to draw on the advice and experience of the whole; by bringing together individuals with compatible ideas and complementary resources; and by binding the Singularitarians into a community.}}</ref>
|-
| 1999 || {{dts|September 17}} || || The Singularitarian mailing list is first informed (by Yudkowsky?) of "The Plan to Singularity" (called "Creating the Singularity" at the time).<ref name="plan_to_singularity_20011121" />
|-
| 2000 || {{dts|January 1}} || Publication || "The Plan to Singularity" version 1.0 is written and published by Eliezer Yudkowsky, and posted to the Singularitarian, Extropians, and transhuman mailing lists.<ref name="plan_to_singularity_20011121">{{cite web |url=https://web.archive.org/web/20011121184414/http://sysopmind.com:80/sing/PtS/meta/versions.html |author=Eliezer S. Yudkowsky |title=PtS: Version History |accessdate=July 4, 2017}}</ref>
|-
| 2000 || {{dts|January 1}} || Publication || "The Singularitarian Principles" version 1.0 by Eliezer Yudkowsky is published.<ref>{{cite web |url=https://web.archive.org/web/20010124225400/http://sysopmind.com:80/sing/principles.html |author=Eliezer S. Yudkowsky |title=Singularitarian Principles 1.0 |accessdate=July 5, 2017}}</ref>
|-
| 2000 || {{dts|February 6}} || || The first email is sent on SL4 ("Shock Level Four"), a mailing list about transhumanism, superintelligent AI, existential risks, and so on.<ref>{{cite web |url=http://sl4.org/archive/date.html |title=SL4: By Date |accessdate=June 1, 2017}}</ref><ref>{{cite web |url=http://sl4.org/ |author=Eliezer S. Yudkowsky |title=SL4 Mailing List |accessdate=June 1, 2017}}</ref>
|-
| 2000 || {{dts|May 18}} || Publication || "Coding a Transhuman AI" (CaTAI) version 2.0a is "rushed out in time for the Foresight Gathering".<ref name="CaTAI_20010202">{{cite web |url=https://web.archive.org/web/20010202042100/http://singinst.org:80/CaTAI.html#version |author=Eliezer S. Yudkowsky |title=Coding a Transhuman AI § Version History |accessdate=July 5, 2017}}</ref>
|-
| 2000 || {{dts|July 27}} || Mission || [[wikipedia:Machine Intelligence Research Institute|Machine Intelligence Research Institute]] is founded as the Singularity Institute for Artificial Intelligence by Brian Atkins, Sabine Atkins (then Sabine Stoeckel) and Eliezer Yudkowsky. The organization's mission ("organization's primary exempt purpose" on Form 990) at the time is "Create a Friendly, self-improving Artificial Intelligence"; this mission would be in use during 2000–2006 and would change in 2007.<ref>{{cite web |url=https://intelligence.org/files/2000-SIAI990.pdf |title=Form 990-EZ 2000 |accessdate=June 1, 2017 |quote=Organization was incorporated in July 2000 and does not have a financial history for years 1996-1999.}}</ref>{{rp|3}}<ref>{{cite web |url=https://web.archive.org/web/20060704101132/http://www.singinst.org:80/about.html |title=About the Singularity Institute for Artificial Intelligence |accessdate=July 1, 2017 |quote=The Singularity Institute for Artificial Intelligence, Inc. (SIAI) was incorporated on July 27th, 2000 by Brian Atkins, Sabine Atkins (then Sabine Stoeckel) and Eliezer Yudkowsky. The Singularity Institute is a nonprofit corporation governed by the Georgia Nonprofit Corporation Code, and is federally tax-exempt as a 501(c)(3) public charity. At this time, the Singularity Institute is funded solely by individual donors.}}</ref>
|-
| 2000 || {{dts|September 1}} || Publication || Large parts of "The Plan to Singularity" are marked obsolete "due to formation of Singularity Institute, and due to fundamental shifts in AI strategy caused by publication of CaTAI [Coding a Transhuman AI] 2".<ref name="plan_to_singularity_20011121" />
|-
| 2000 || {{dts|September 7}} || Publication || "Coding a Transhuman AI" (CaTAI) version 2.2.0 is published.<ref name="CaTAI_20010202" />
|-
| 2000 || {{dts|September 14}} || || The first Wayback Machine snapshot of MIRI's website is from this day, using the <code>singinst.org</code> domain name.<ref>{{cite web |url=https://web.archive.org/web/20000914073559/http://www.singinst.org:80/ |author=Eliezer S. Yudkowsky |title=Singularity Institute for Artificial Intelligence, Inc. |accessdate=July 4, 2017}}</ref>
|-
| 2001 || {{dts|April 8}} || || MIRI begins accepting donations after receiving tax-exempt status.<ref>{{cite web |url=https://web.archive.org/web/20010422041823/http://singinst.org:80/news.html |author=Eliezer S. Yudkowsky |title=Singularity Institute: News |accessdate=July 1, 2017 |quote=April 08, 2001: The Singularity Institute for Artificial Intelligence, Inc. announces that it has received tax-exempt status and is now accepting donations.}}</ref>
|-
| 2001 || {{dts|April 18}} || Publication || Version 0.9 of "Creating Friendly AI" is released.<ref name="siai_news_archive_jun_2004">{{cite web |url=https://web.archive.org/web/20040607135521/http://singinst.org:80/news/archive.html |title=Singularity Institute for Artificial Intelligence // News // Archive |accessdate=July 13, 2017}}</ref>
|-
| 2001 || {{dts|June 14}} || Publication || The "SIAI Guidelines on Friendly AI" are published.<ref>{{cite web |url=https://web.archive.org/web/20010805005837/http://singinst.org:80/friendly/guidelines.html |author=Singularity Institute for Artificial Intelligence |title=SIAI Guidelines on Friendly AI |accessdate=July 13, 2017}}</ref>
|-
| 2001 || {{dts|June 15}} || Publication || Version 1.0 of "Creating Friendly AI" is published.<ref>{{cite web |url=https://intelligence.org/files/CFAI.pdf |title=Creating Friendly AI 1.0: The Analysis and Design of Benevolent Goal Architectures |year=2001 |author=Eliezer Yudkowsky |publisher=The Singularity Institute |accessdate=July 5, 2017}}</ref><ref name="siai_news_archive_jun_2004" />
|-
| 2001 || {{dts|July 23}} || Project || MIRI announces that it has formally launched the development of the Flare programming language under Dmitriy Myshkin.<ref name="singinst_jun_2003_news" />
|-
| 2001 || {{dts|December 21}} || Domain || MIRI obtains the <code>flare.org</code> domain name for its Flare language project.<ref name="singinst_jun_2003_news" />
|-
| 2002 || {{dts|March 8}} || AI box || The first [[wikipedia:AI box|AI box]] experiment by Eliezer Yudkowsky, against Nathan Russell as gatekeeper, takes place. The AI is released.<ref>{{cite web |url=http://www.sl4.org/archive/0203/index.html#3128 |title=SL4: By Thread |accessdate=July 1, 2017}}</ref>
|-
| 2002 || {{dts|April 7}} || Publication || A draft of "Levels of Organization in General Intelligence" is announced on SL4.<ref>{{cite web |url=http://www.sl4.org/archive/0204/3296.html |author=Eliezer S. Yudkowsky |date=April 7, 2002 |title=SL4: PAPER: Levels of Organization in General Intelligence |accessdate=July 5, 2017}}</ref><ref>{{cite web |url=https://web.archive.org/web/20120722082136/singularity.org/upload/LOGI/index.html |author=Singularity Institute for Artificial Intelligence |title=Levels of Organization in General Intelligence |accessdate=July 5, 2017}}</ref>
|-
| 2002 || {{dts|July 4}}–5 || AI box || The second AI box experiment by Eliezer Yudkowsky, against David McFadzean as gatekeeper, takes place. The AI is released.<ref>{{cite web |url=http://www.sl4.org/archive/0207/index.html#4689 |title=SL4: By Thread |accessdate=July 1, 2017}}</ref>
|-
| 2002 || {{dts|September 6}} || Staff || Christian Rovner is appointed as MIRI's volunteer coordinator.<ref name="singinst_jun_2003_news" />
|-
| 2002 || {{dts|October 1}} || || MIRI "releases a major new site upgrade" with various new pages.<ref name="singinst_jun_2003_news" />
|-
| 2002 || {{dts|October 7}} || Project || MIRI announces the creation of its volunteers mailing list.<ref name="singinst_jun_2003_news">{{cite web |url=https://web.archive.org/web/20030622011438/http://singinst.org:80/news/ |author=Eliezer S. Yudkowsky |title=Singularity Institute: News |accessdate=July 1, 2017}}</ref>
|-
| 2003 || || Project || The Flare Programming language project is officially canceled.<ref>{{cite web |url=http://www.sl4.org/wiki/FlareProgrammingLanguage |website=SL4 Wiki |title=FlareProgrammingLanguage |date=September 14, 2007 |accessdate=July 13, 2017}}</ref>
|-
| 2003 || || Publication || Eliezer Yudkowsky's "An Intuitive Explanation of Bayesian Reasoning" is published.<ref>{{cite web |url=http://yudkowsky.net/rational/bayes |title=Yudkowsky - Bayes' Theorem |accessdate=July 5, 2017 |quote=Eliezer Yudkowsky's work is supported by the Machine Intelligence Research Institute. If you've found Yudkowsky's pages on rationality useful, please consider donating to the Machine Intelligence Research Institute.}}</ref>
|-
| 2004 || {{dts|March 4}}–11 || Staff || MIRI announces Tyler Emerson as executive director.<ref name="singinst_feb_2006_news">{{cite web |url=https://web.archive.org/web/20060220211402/http://www.singinst.org:80/news/ |title=News of the Singularity Institute for Artificial Intelligence |accessdate=July 4, 2017}}</ref><ref>{{cite web |url=https://web.archive.org/web/20061004202026/http://www.singinst.org/news/newsletter.html#3 |title=Singularity Institute for Artificial Intelligence // The SIAI Voice |accessdate=July 4, 2017 |quote=On March 4, 2004, the Singularity Institute announced Tyler Emerson as our Executive Director. Emerson will be responsible for guiding the Institute. His focus is in nonprofit management, marketing, relationship fundraising, leadership and planning. He will seek to cultivate a larger and more cohesive community that has the necessary resources to develop Friendly AI.}}</ref>
|-
| 2004 || {{dts|April 7}} || Staff || Michael Anissimov is announced as MIRI's advocacy director.<ref>{{cite web |url=http://sl4.org/archive/0404/8447.html |author=Tyler Emerson |date=April 7, 2004 |title=SL4: Michael Anissimov - SIAI Advocacy Director |accessdate=July 1, 2017 |quote=The Singularity Institute announces Michael Anissimov as our Advocacy Director. Michael has been an active volunteer for two years, and one of the more prominent voices in the singularity community. He is committed and thoughtful, and we feel very fortunate to have him help lead our advocacy.}}</ref>
|-
| 2004 || {{dts|May}} || Publication || Eliezer Yudkowsky's paper "Coherent Extrapolated Volition" is published around this time.<ref>{{cite web |url=https://intelligence.org/files/CEV.pdf |title=Coherent Extrapolated Volition |author=Eliezer Yudkowsky |accessdate=July 1, 2017 |quote=The information is current as of May 2004, and should not become dreadfully obsolete until late June, when I plant to have an unexpected insight.}}</ref> It is originally called "Collective Volition", and is announced on the MIRI website on August 16.<ref>{{cite web |url=https://web.archive.org/web/20040623153032/http://www.singinst.org/friendly/collective-volition.html |title=Collective Volition |accessdate=July 4, 2017}}</ref><ref name="singinst_feb_2006_news" />
|-
| 2004 || {{dts|August 5}}–8 || Conference || TransVision 2004 takes place. TransVision is the World Transhumanist Association's annual event. MIRI is a sponsor for the event.<ref name="singinst_feb_2006_news" />
|-
| 2005 || {{dts|January 4}} || Publication || "A Technical Explanation of Technical Explanation" is published.<ref>{{cite web |url=http://yudkowsky.net/rational/technical |title=Yudkowsky - Technical Explanation |accessdate=July 5, 2017 |quote=Eliezer Yudkowsky's work is supported by the Machine Intelligence Research Institute.}}</ref> It is announced on the MIRI news page on this day.<ref name="singinst_feb_2006_news" />
|-
| 2005 || || Conference || MIRI does "AI and existential risk presentations at Stanford, Immortality Institute's Life Extension Conference, and the Terasem Foundation".<ref name="siai_an_examination" />
|-
| 2005 || || Publication || Eliezer Yudkowsky writes chapters for ''[[wikipedia:Global Catastrophic Risks (book)|Global Catastrophic Risks]]'', edited by [[wikipedia:Nick Bostrom|Nick Bostrom]] and Milan M. Ćirković.<ref name="siai_an_examination" /> The book would be published in 2008.
|-
| 2005 || {{dts|February 2}} || || MIRI relocates from the [[wikipedia:Atlanta metropolitan area|Atlanta metropolitan area]] of Georgia to the Bay Area of California.<ref name="singinst_feb_2006_news" />
|-
| 2005 || {{dts|July 22}}–24 || Conference || TransVision 2005 takes place in Caracas, Venezuela. MIRI is a sponsor for the event.<ref name="singinst_feb_2006_news" />
|-
| 2005 || {{dts|August 21}} || AI box || The third AI box experiment by Eliezer Yudkowsky, against Carl Shulman as gatekeeper, takes place. The AI is released.<ref>{{cite web |url=http://sl4.org/archive/0508/index.html#12007 |title=SL4: By Thread |accessdate=July 1, 2017}}</ref>
|-
| 2005–2006 || {{dts|December 20, 2005}}{{snd}}{{dts|February 19, 2006}} || Financial || The 2006 $100,000 Singularity Challenge, a fundraiser in which [[wikipedia:Peter Thiel|Peter Thiel]] matches donations up to $100,000, takes place. The fundraiser successfully matches the $100,000 amount.<ref name="singinst_feb_2006_news" /><ref>{{cite web |url=https://web.archive.org/web/20060207074758/http://www.singinst.org:80/challenge/ |title=The Singularity Institute for Artificial Intelligence - 2006 $100,000 Singularity Challenge |accessdate=July 5, 2017}}</ref>
|-
| 2006 || || Publication || "Twelve Virtues of Rationality" is published.<ref>{{cite web |url=http://yudkowsky.net/rational/virtues |title=Twelve Virtues of Rationality |accessdate=July 5, 2017 |quote=Eliezer Yudkowsky's work is supported by the Machine Intelligence Research Institute.}}</ref>
|-
| 2006 || {{dts|February 13}} || || [[wikipedia:Peter Thiel|Peter Thiel]] joins MIRI's Board of Advisors.<ref name="singinst_feb_2006_news" />
|-
| 2006 || {{dts|May 13}} || Conference || The first Singularity Summit takes place at Stanford University.<ref name="miri_singularity_summit">{{cite web |url=https://intelligence.org/singularitysummit/ |title=Singularity Summit |publisher=Machine Intelligence Research Institute |accessdate=June 30, 2017}}</ref><ref>{{cite web |url=http://www.zdnet.com/article/the-great-singularity-debate/ |publisher=ZDNet |title=The great Singularity debate |author=Dan Farber |accessdate=June 30, 2017}}</ref><ref>{{cite web |url=http://www.jerrypournelle.com/reports/jerryp/singularity.html |author=Jerry Pournelle |title=Chaos Manor Special Reports: The Stanford Singularity Summit |date=May 20, 2006 |accessdate=June 30, 2017}}</ref>
|-
| 2006 || {{dts|November}} || || [[wikipedia:Robin Hanson|Robin Hanson]] starts ''[[wikipedia:Overcoming Bias|Overcoming Bias]]''.<ref>{{cite web |url=http://www.overcomingbias.com/bio |title=Overcoming Bias : Bio |accessdate=June 1, 2017}}</ref>
|-
| 2007 || || Mission || MIRI's organization mission ("Organization's Primary Exempt Purpose" on Form 990) changes to: "To develop safe, stable and self-modifying Artificial General Intelligence. And to support novel research and to foster the creation of a research community focused on Artificial General Intelligence and Safe and Friendly Artificial Intelligence."<ref>{{cite web |url=https://intelligence.org/files/2007-SIAI990.pdf |title=Form 990 2007 |accessdate=July 8, 2017}}</ref> This mission would be used in 2008 and 2009 as well.
|-
| 2007 || || Project || MIRI's outreach blog is started.<ref name="siai_an_examination" />
|-
| 2007 || || Project || MIRI's Interview Series is started.<ref name="siai_an_examination" />
|-
| 2007 || {{dts|May 16}} || Project || MIRI's introductory video is published on YouTube.<ref>{{cite web |url=https://www.youtube.com/watch?v=0A9pGhwQbS0 |title=Singularity Institute for Artificial Intelligence |publisher=YouTube |accessdate=July 8, 2017}}</ref><ref name="siai_an_examination" />
|-
| 2007 || {{dts|September 8}}–9  || Conference || The Singularity Summit 2007 takes place in the San Francisco Bay Area.<ref name="miri_singularity_summit" /><ref>{{cite web |url=https://web.archive.org/web/20080331205725/http://www.singinst.org:80/summit2007/ |title=The Singularity Summit 2007 |accessdate=June 30, 2017}}</ref><ref>{{cite web |url=http://www.foxnews.com/story/2007/09/12/scientists-fear-day-computers-become-smarter-than-humans.html |title=Scientists Fear Day Computers Become Smarter Than Humans |publisher=Fox News |accessdate=July 5, 2017 |date=September 12, 2007 |quote=futurists gathered Saturday for a weekend conference}}</ref>
|-
| 2008 || || Publication || "The Simple Truth" is published.<ref>{{cite web |url=http://yudkowsky.net/rational/the-simple-truth |title=Yudkowsky - The Simple Truth |accessdate=July 5, 2017 |quote=Eliezer Yudkowsky's work is supported by the Machine Intelligence Research Institute.}}</ref>
|-
| 2008 || || Project || MIRI expands its Interview Series.<ref name="siai_an_examination" />
|-
| 2008 || || Project || MIRI begins its summer intern program.<ref name="siai_an_examination" />
|-
| 2008 || || Project || [[wikipedia:OpenCog|OpenCog]] is founded "via a grant from the [MIRI], and the donation from Novamente LLC of a large body of software code and software designs developed during the period 2001–2007".<ref>{{cite web |url=http://opencog.org/about/ |publisher=OpenCog Foundation |title=About |accessdate=July 6, 2017}}</ref> (See also [[wikipedia:OpenCog#Relation to Singularity Institute|OpenCog § Relation to Singularity Institute]].)
|-
| 2008 || {{dts|October 25}} || Conference || The Singularity Summit 2008 takes place in San Jose.<ref>{{cite web |url=https://web.archive.org/web/20090608082235/http://www.singularitysummit.com/program |author=http://helldesign.net |title=The Singularity Summit 2008: Opportunity, Risk, Leadership &gt; Program |accessdate=June 30, 2017}}</ref><ref>{{cite web |url=http://www.mercurynews.com/2008/10/23/annual-a-i-conference-to-be-held-this-saturday-in-san-jose/ |title=Annual A.I. conference to be held this Saturday in San Jose |date=October 23, 2008 |author=Elise Ackerman |publisher=The Mercury News |accessdate=July 5, 2017}}</ref>
|-
| 2008 || {{dts|November}}–December || Outside review || The AI-Foom debate between Robin Hanson and Eliezer Yudkowsky takes place. The blog posts from the debate would later be turned into an ebook by MIRI.<ref>{{cite web |url=https://wiki.lesswrong.com/wiki/The_Hanson-Yudkowsky_AI-Foom_Debate |title=The Hanson-Yudkowsky AI-Foom Debate |website=Lesswrongwiki |accessdate=July 1, 2017 |publisher=[[wikipedia:LessWrong|LessWrong]]}}</ref><ref>{{cite web |url=http://lesswrong.com/lw/cbs/thoughts_on_the_singularity_institute_si/6k1b |title=Eliezer_Yudkowsky comments on Thoughts on the Singularity Institute (SI) - Less Wrong |accessdate=July 15, 2017 |quote=Nonetheless, it already has a warm place in my heart next to the debate with Robin Hanson as the second attempt to mount informed criticism of SIAI. |publisher=[[wikipedia:LessWrong|LessWrong]]}}</ref>
|-
| 2009 || || Project || MIRI establishes the Visiting Fellows Program.<ref name="siai_an_examination" />
|-
| 2009 (early) || || Staff || Executive director Tyler Emerson departs MIRI.<ref name="siai_accomplishments_20110621">{{cite web |url=https://web.archive.org/web/20110621192259/http://singinst.org/achievements |title=Recent Singularity Institute Accomplishments |publisher=Singularity Institute for Artificial Intelligence |accessdate=July 6, 2017}}</ref>
|-
| 2009 (early) || || Staff || Michael Anissimov is hired as a media director.<ref name="siai_accomplishments_20110621" /> (Since he was advocacy director as far back as 2004, it's not clear if he left the organization and came back, or if just changed positions.)
|-
| 2009 || {{dts|February}} || Project || Eliezer Yudkowsky starts LessWrong using as seed material his posts on Overcoming Bias.<ref>{{cite web |url=https://wiki.lesswrong.com/wiki/FAQ#Where_did_Less_Wrong_come_from.3F |title=FAQ - Lesswrongwiki |accessdate=June 1, 2017 |publisher=[[wikipedia:LessWrong|LessWrong]]}}</ref> On the 2009 accomplishments page, MIRI describes LessWrong as being "important to the Singularity Institute's work towards a beneficial Singularity in providing an introduction to issues of cognitive biases and rationality relevant for careful thinking about optimal philanthropy and many of the problems that must be solved in advance of the creation of provably human-friendly powerful artificial intelligence". And: "Besides providing a home for an intellectual community dialoguing on rationality and decision theory, ''Less Wrong'' is also a key venue for SIAI recruitment.  Many of the participants in SIAI's Visiting Fellows Program first discovered the organization through ''Less Wrong''."<ref name="siai_accomplishments_20110621" />
|-
| 2009 || {{dts|February 16}} || Staff || Michael Vassar announces himself as president of MIRI.<ref>{{cite web |url=https://intelligence.org/2009/02/16/introducing-myself/ |title=Introducing Myself |author=Michael Vassar |publisher=Machine Intelligence Research Institute |date=February 16, 2009 |accessdate=July 1, 2017}}</ref>
|-
| 2009 || {{dts|April}} || Publication || Eliezer Yudkowsky completes the Sequences.<ref name="siai_accomplishments_20110621" />
|-
| 2009 || {{dts|August 13}} || Social media || The Singularity Institute Twitter account, singinst, is created.<ref>{{cite web |url=https://twitter.com/singinst |title=SingularityInstitute (@singinst) |publisher=Twitter |accessdate=July 4, 2017}}</ref>
|-
| 2009 || {{dts|October}} || Project || A website maintained by MIRI, ''The Uncertain Future'', first appears around this time.<ref>{{cite web |url=https://web.archive.org/web/20090101000000*/http://theuncertainfuture.com/ |title=Wayback Machine |accessdate=July 2, 2017}} The first snapshot is from October 5, 2009.</ref><ref>{{cite web |url=https://www.google.com/search?q=http%3A%2F%2Ftheuncertainfuture.com%2F&source=lnt&tbs=cdr%3A1%2Ccd_min%3A1%2F1%2F2009%2Ccd_max%3A1%2F1%2F2010&tbm= |title=theuncertainfuture.com - Google Search |accessdate=July 2, 2017}} The earliest cache seems to be from October 25, 2009. Checking the Jan 1, 2008 – Jan 1, 2009 range produces no result.</ref> The goal of the website is to "allow those interested in future technology to form their own rigorous, mathematically consistent model of how the development of advanced technologies will affect the evolution of civilization over the next hundred years".<ref>{{cite web |url=http://theuncertainfuture.com/ |title=The Uncertain Future |accessdate=July 2, 2017 |publisher=Machine Intelligence Research Institute}}</ref>
|-
| 2009 || {{dts|October 3}}–4 || Conference || The Singularity Summit 2009 takes place in New York.<ref>{{cite web |url=https://web.archive.org/web/20091217213848/http://www.singularitysummit.com/program |author=http://helldesign.net |title=The Singularity Summit 2009 &gt; Program |accessdate=June 30, 2017}}</ref><ref>{{cite web |url=http://www.popsci.com/scitech/article/2009-10/singularity-summit-2009-singularity-near |publisher=Popular Science |title=Singularity Summit 2009: The Singularity Is Near |accessdate=June 30, 2017 |date=October 2, 2009 |author=Stuart Fox}}</ref>
|-
| 2009 || {{dts|November}} || Financial || "Misappropriation of assets, by a contractor, was discovered in November 2009."<ref>{{cite web |url=https://intelligence.org/files/2009-SIAI990.pdf |title=Form 990 2009 |accessdate=July 8, 2017}}</ref>
|-
| 2009 || {{dts|December}} || Staff || Amy Willey joins MIRI as Chief Compliance Officer.<ref name="siai_accomplishments_20110621" />
|-
| 2009 || {{dts|December 11}} || Influence || The third edition of ''[[wikipedia:Artificial Intelligence: A Modern Approach|Artificial Intelligence: A Modern Approach]]'' by [[wikipedia:Stuart J. Russell|Stuart J. Russell]] and [[wikipedia:Peter Norvig|Peter Norvig]] is published. In this edition, for the first time, Friendly AI is mentioned and Eliezer Yudkowsky is cited.
|-
| 2009 || {{dts|December 12}} || Project || ''The Uncertain Future'' reaches [[wikipedia:Software release life cycle#Beta|beta]] and is announced on the MIRI blog.<ref>{{cite web |url=https://web.archive.org/web/20100507142148/http://www.singinst.org:80/blog/2009/12/12/the-uncertain-future/ |author=Michael Anissimov |website=The Singularity Institute Blog |title=The Uncertain Future |date=December 12, 1009 |accessdate=July 5, 2017}}</ref>
|-
| 2009 || || Financial || MIRI reports $118,803.00 in theft during this year.<ref name="siai_an_examination">{{cite web |url=http://lesswrong.com/lw/5il/siai_an_examination/ |title=SIAI - An Examination - Less Wrong |accessdate=June 30, 2017 |author=Brandon Reinhart |publisher=[[wikipedia:LessWrong|LessWrong]]}}</ref><ref>{{cite web |url=http://lesswrong.com/lw/cbs/thoughts_on_the_singularity_institute_si/6jzn |title=lukeprog comments on Thoughts on the Singularity Institute (SI) - Less Wrong |accessdate=June 30, 2017 |quote=So little monitoring of funds that $118k was stolen in 2010 before SI noticed. (Note that we have won stipulated judgments to get much of this back, and have upcoming court dates to argue for stipulated judgments to get the rest back.) |publisher=[[wikipedia:LessWrong|LessWrong]]}}</ref><ref>{{cite web |url=http://lesswrong.com/r/discussion/lw/5fo/siai_fundraising/4156 |title=cjb comments on SIAI Fundraising  |accessdate=July 8, 2017 |publisher=[[wikipedia:LessWrong|LessWrong]]}}</ref><ref>{{cite web |url=https://web.archive.org/web/20100116020241/http://www.almanacnews.com/story.php?story_id=9028 |title=Almanac Almanac: Police Calls (December 23, 2009) |accessdate=July 8, 2017 |quote=Embezzlement report: Alicia Issac, 37, of Sunnyvale arrested on embezzlement, larceny and conspiracy charges in connection with $51,000 loss, Singularity Institute for Artificial Intelligence in 1400 block of Adams Drive, Dec. 10.}}</ref> The theft was by two former employees.<ref>{{cite web |url=http://lesswrong.com/lw/di4/reply_to_holden_on_the_singularity_institute/ |title=Reply to Holden on The Singularity Institute |date=July 10, 2012 |accessdate=June 30, 2017 |publisher=[[wikipedia:LessWrong|LessWrong]] |quote=Two former employees stole $118,000 from SI. Earlier this year we finally won stipulated judgments against both individuals, forcing them to pay back the full amounts they stole. We have already recovered several thousand dollars of this.}}</ref>
|-
| 2010 || || Mission || The organization mission changes to: "To develop the theory and particulars of safe self-improving Artificial Intelligence; to support novel research and foster the creation of a research community focused on safe Artificial General Intelligence; and to otherwise improve the probability of humanity surviving future technological advances."<ref>{{cite web |url=https://intelligence.org/files/2010-SIAI990.pdf |title=Form 990 2010 |accessdate=July 8, 2017}}</ref> This mission would be used in 2011 and 2012 as well.
|-
| 2010 || {{dts|February 28}} || Publication || The first chapter of Eliezer Yudkowsky's fan fiction ''[[wikipedia:Harry Potter and the Methods of Rationality|Harry Potter and the Methods of Rationality]]'' is published. The book would be published as a serial concluding on March 14, 2015.<ref>{{cite web |url=https://www.fanfiction.net/s/5782108/1/Harry-Potter-and-the-Methods-of-Rationality |title=Harry Potter and the Methods of Rationality Chapter 1: A Day of Very Low Probability, a harry potter fanfic |publisher=FanFiction |accessdate=July 1, 2017 |quote=Updated: 3/14/2015 - Published: 2/28/2010}}</ref><ref>{{cite web |url=https://www.vice.com/en_us/article/gq84xy/theres-something-weird-happening-in-the-world-of-harry-potter-168 |publisher=Vice |title=The Harry Potter Fan Fiction Author Who Wants to Make Everyone a Little More Rational |date=March 2, 2015 |author=David Whelan |accessdate=July 1, 2017}}</ref> The fan fiction would become the initial contact with MIRI of several larger donors to MIRI.<ref>{{cite web |url=https://intelligence.org/2014/04/02/2013-in-review-fundraising/#identifier_2_10812 |title=2013 in Review: Fundraising - Machine Intelligence Research Institute |publisher=Machine Intelligence Research Institute |date=August 13, 2014 |accessdate=July 1, 2017 |quote=Recently, we asked (nearly) every donor who gave more than $3,000 in 2013 about the source of their initial contact with MIRI, their reasons for donating in 2013, and their preferred methods for staying in contact with MIRI. [&hellip] Four came into contact with MIRI via HPMoR.}}</ref>
|-
| 2010 || {{dts|August 14}}–15 || Conference || The Singularity Summit 2010 takes place in San Francisco.<ref>{{cite web |url=https://web.archive.org/web/20110107222220/http://www.singularitysummit.com/program |title=Singularity Summit {{!}} Program |accessdate=June 30, 2017}}</ref>
|-
| 2010 || {{dts|December 21}} || Social media || The first post on the MIRI Facebook page is from this day.<ref>{{cite web |url=https://www.facebook.com/MachineIntelligenceResearchInstitute/posts/176049615748742 |title=Machine Intelligence Research Institute - Posts |accessdate=July 4, 2017}}</ref><ref>{{cite web |url=https://www.facebook.com/pg/MachineIntelligenceResearchInstitute/posts/?ref=page_internal |title=Machine Intelligence Research Institute - Posts |accessdate=July 4, 2017}}</ref>
|-
| 2010–2011 || {{dts|December 21, 2010}}{{snd}}{{dts|January 20, 2011}} || Financial || The Tallinn–Evans $125,000 Singularity Challenge takes place. The Challenge is a fundraiser in which Edwin Evans and Jaan Tallinn match each dollar donated to MIRI up to $125,000.<ref>{{cite web |url=https://intelligence.org/2010/12/21/announcing-the-tallinn-evans-125000-singularity-holiday-challenge/ |title=Announcing the Tallinn-Evans $125,000 Singularity Challenge |author=Louie Helm |publisher=Machine Intelligence Research Institute |date=December 21, 2010 |accessdate=July 7, 2017}}</ref><ref>{{cite web |url=http://lesswrong.com/lw/3gy/tallinnevans_125000_singularity_challenge/ |title=Tallinn-Evans $125,000 Singularity Challenge |date=December 26, 2010 |author=Kaj Sotala |accessdate=July 7, 2017 |publisher=[[wikipedia:LessWrong|LessWrong]]}}</ref>
|-
| 2011 || {{dts|February}} || Outside review || Holden Karnofsky of GiveWell has a conversation with MIRI staff. The conversation reveals the existence of a "Persistent Problems Group" at MIRI, which will supposedly "assemble a blue-ribbon panel of recognizable experts to make sense of the academic literature on very applicable, popular, but poorly understood topics such as diet/nutrition".<ref>{{cite web |url=http://www.givewell.org/files/MiscCharities/SIAI/siai%202011%2002%20III.doc |title=GiveWell conversation with SIAI |date=February 2011 |publisher=GiveWell |accessdate=July 4, 2017}}</ref> On April 30, Karnofsky would post the conversation to the GiveWell mailing list.<ref>{{cite web |url=https://groups.yahoo.com/neo/groups/givewell/conversations/topics/270 |publisher=Yahoo! Groups |title=Singularity Institute for Artificial Intelligence |author=Holden Karnofsky |accessdate=July 4, 2017}}</ref>
|-
| 2011 || {{dts|April}} || Staff || Luke Muehlhauser begins as an intern at MIRI.<ref>{{cite web |url=http://lesswrong.com/lw/cbs/thoughts_on_the_singularity_institute_si/6l4h |title=lukeprog comments on Thoughts on the Singularity Institute (SI) |accessdate=June 30, 2017 |quote=When I began to intern with the Singularity Institute in April 2011, I felt uncomfortable suggesting that people donate to SingInst, because I could see it from the inside and it wasn't pretty. |publisher=[[wikipedia:LessWrong|LessWrong]]}}</ref>
|-
| 2011 || {{dts|May 10}}{{snd}}{{dts|June 24}} || Outside review || Holden Karnofsky of GiveWell and [[wikipedia:Jaan Tallinn|Jaan Tallinn]] (with Dario Amodei being present in the initial phone conversation) correspond regarding MIRI's work. The correspondence is posted to the GiveWell mailing list on July 18.<ref>{{cite web |url=https://groups.yahoo.com/neo/groups/givewell/conversations/messages/287 |title=Re: [givewell] Singularity Institute for Artificial Intelligence |author=Holden Karnofsky |publisher=Yahoo! Groups |accessdate=July 4, 2017}}</ref>
|-
| 2011 || {{dts|June 24}} || Domain || A Wayback Machine snapshot on this day shows that <code>singularity.org</code> has turned into a GoDaddy.com placeholder.<ref>{{cite web |url=https://web.archive.org/web/20110624011222/http://singularity.org:80/ |title=singularity.org |accessdate=July 4, 2017}}</ref> Before this, the domain is some blog, most likely unrelated to MIRI.<ref name="singularity_org_2011">{{cite web |url=https://web.archive.org/web/20111001000000*/singularity.org |title=Wayback Machine |accessdate=July 4, 2017}}</ref>
|-
| 2011 || {{dts|July 18}}{{snd}}{{dts|October 20}} || Domain || At least during this period, the <code>singularity.org</code> domain name redirects to <code>singinst.org/singularityfaq</code>.<ref name="singularity_org_2011" />
|-
| 2011 || {{dts|September 6}} || Domain || The first Wayback Machine capture of <code>singularityvolunteers.org</code> is from this day.<ref>{{cite web |url=https://web.archive.org/web/20110906193713/http://www.singularityvolunteers.org/ |title=Singularity Institute Volunteering |accessdate=July 14, 2017}}</ref> For a time the site is used to coordinate volunteer efforts.
|-
| 2011 || {{dts|October 15}}–16 || Conference || The Singularity Summit 2011 takes place in New York.<ref>{{cite web |url=https://web.archive.org/web/20111031090701/http://www.singularitysummit.com:80/program |title=Singularity Summit {{!}} Program |accessdate=June 30, 2017}}</ref>
|-
| 2011 || {{dts|October 17}} || Social media || The Singularity Summit YouTube account, SingularitySummits, is created.<ref>{{cite web |url=https://www.youtube.com/user/SingularitySummits/about |title=SingularitySummits |publisher=YouTube |accessdate=July 4, 2017 |quote=Joined Oct 17, 2011}}</ref>
|-
| 2011 || {{dts|November}} || Staff || Luke Muehlhauser is appointed executive director of MIRI.<ref>{{cite web |url=https://intelligence.org/2012/01/16/singularity-institute-progress-report-december-2011/ |title=Machine Intelligence Research Institute Progress Report, December 2011 |publisher=Machine Intelligence Research Institute |author=Luke Muehlhauser |date=January 16, 2012 |accessdate=July 14, 2017}}</ref>
|-
| 2011 || {{dts|December 12}} || Project || Luke Muehlhauser announces the creation of Friendly-AI.com, a website introducing the idea of Friendly AI.<ref>{{cite web |url=http://lesswrong.com/lw/8t6/new_landing_page_website_friendlyaicom/ |title=New 'landing page' website: Friendly-AI.com |author=lukeprog |date=December 12, 2011 |accessdate=July 2, 2017 |publisher=[[wikipedia:LessWrong|LessWrong]]}}</ref>
|-
| 2012 || {{dts|February 4}}{{snd}}{{dts|May 4}} || Domain || At least during this period, <code>singularity.org</code> redirects to <code>singinst.org</code>.<ref>{{cite web |url=https://web.archive.org/web/20120501000000*/singularity.org |title=Wayback Machine |accessdate=July 4, 2017}}</ref>
|-
| 2012 || {{dts|May 8}} || || MIRI's April 2012 progress report is published, in which the Center for Applied Rationality's name is announced. Until this point, CFAR was known as the "Rationality Group" or "Rationality Org".<ref>{{cite web |url=https://intelligence.org/2012/05/08/singularity-institute-progress-report-april-2012/ |title=Machine Intelligence Research Institute Progress Report, April 2012 |publisher=Machine Intelligence Research Institute |date=May 8, 2012 |author=Louie Helm |accessdate=June 30, 2017}}</ref>
|-
| 2012 || {{dts|May 11}} || Outside review || Holden Karnofsky publishes "Thoughts on the Singularity Institute (SI)" on [[wikipedia:LessWrong|LessWrong]]. The post explains why GiveWell does not plan to recommend the Singularity Institute.<ref>{{cite web |url=http://lesswrong.com/lw/cbs/thoughts_on_the_singularity_institute_si/ |title=Thoughts on the Singularity Institute (SI) - Less Wrong |accessdate=June 30, 2017 |author=Holden Karnofsky |publisher=[[wikipedia:LessWrong|LessWrong]]}}</ref>
|-
| 2012 || {{dts|June 16}}–28 || Domain || Sometime during this period, <code>singinst.org</code> begins redirecting to <code>singularity.org</code>, both being controlled by MIRI.<ref>{{cite web |url=https://web.archive.org/web/20120601000000*/singinst.org |title=Wayback Machine |accessdate=July 4, 2017}}</ref>
|-
| 2012 || {{dts|August 15}} || || Luke Muehlhauser does an "ask me anything" (AMA) on reddit's r/Futurology.<ref>{{cite web |url=https://www.reddit.com/r/Futurology/comments/y9lm0/i_am_luke_muehlhauser_ceo_of_the_singularity/ |publisher=reddit |title=I am Luke Muehlhauser, CEO of the Singularity Institute for Artificial Intelligence. Ask me anything about the Singularity, AI progress, technological forecasting, and researching Friendly AI! • r/Futurology |accessdate=June 30, 2017}}</ref>
|-
| 2012 || {{dts|September}} (approximate) || Project || MIRI begins to partner with Youtopia as its volunteer management platform.<ref>{{cite web |url=https://intelligence.org/2012/11/07/november-2012-newsletter/ |title=November 2012 Newsletter |publisher=Machine Intelligence Research Institute |date=November 7, 2012 |accessdate=July 14, 2017 |quote=Over the past couple of months we thought hard about how to improve our volunteer program, with the goal of finding a system that makes it easier to engage volunteers, create a sense of community, and quantify volunteer contributions. After evaluating several different volunteer management platforms, we decided to partner with Youtopia — a young company with a lot of promise — and make heavy use of Google Docs.}}</ref>
|-
| 2012 || {{dts|October 13}}–14 || Conference || The Singularity Summit 2012 takes place.<ref>{{cite web |url=https://singularityhub.com/2012/08/29/singularity-summit-2012-is-coming-to-san-francisco-october-13-14/ |author=David J. Hill |title=Singularity Summit 2012 Is Coming To San Francisco October 13-14 |publisher=Singularity Hub |date=August 29, 2012 |accessdate=July 6, 2017}}</ref><ref>{{cite web |url=http://blogs.discovermagazine.com/gnxp/2012/10/singularity-summit-2012-the-lion-doesnt-sleep-tonight/ |title=Singularity Summit 2012: the lion doesn't sleep tonight |website=Gene Expression |publisher=Discover |date=October 15, 2012 |accessdate=July 6, 2017}}</ref>
|-
| 2012 || {{dts|November 11}}–18 || Workshop || The 1st Workshop on Logic, Probability, and Reflection takes place.<ref name="workshops">{{cite web |url=https://intelligence.org/workshops/ |title=Research Workshops - Machine Intelligence Research Institute |publisher=Machine Intelligence Research Institute |accessdate=July 1, 2017}}</ref>
|-
| 2012 || {{dts|December 6}} || || Singularity University announces that it has acquired the Singularity Summit from MIRI.<ref>{{cite web |url=http://singularityu.org/2012/12/09/singularity-university-acquires-the-singularity-summit/ |title=Singularity University Acquires the Singularity Summit |publisher=Singularity University |date=December 9, 2012 |accessdate=June 30, 2017}}</ref>
|-
| 2013 || || Mission || The organization mission changes to: "To ensure that the creation of smarter-than-human intelligence has a positive impact. Thus, the charitable purpose of the organization is to: a) perform research relevant to ensuring that smarter-than-human intelligence has a positive impact; b) raise awareness of this important issue; c) advise researchers, leasers and laypeople around the world; d) as necessary, implement a smarter-than-human intelligence with humane, stable goals."<ref>{{cite web |url=https://intelligence.org/wp-content/uploads/2012/06/2013-990.pdf |title=Form 990 2013 |accessdate=July 8, 2017}}</ref> This mission would stay the same for 2014 and 2015.
|-
| 2013–2014 || || Project || MIRI conducts a lot of conversations during this period. Out of 80 conversations listed as of July 14, 2017, 75 are from this period (19 in 2013 and 56 in 2014).<ref>{{cite web |url=https://intelligence.org/category/conversations/ |title=Conversations Archives |publisher=Machine Intelligence Research Institute |accessdate=July 15, 2017}}</ref> In the "2014 in review" post on MIRI's blog Luke Muehlhauser writes: "Nearly all of the interviews were begun in 2013 or early 2014, even if they were not finished and published until much later. Mid-way through 2014, we decided to de-prioritize expert interviews, due to apparent diminishing returns."<ref>{{cite web |url=https://intelligence.org/2015/03/22/2014-review/ |title=2014 in review |author=Luke Muehlhauser |publisher=Machine Intelligence Research Institute |date=March 22, 2015 |accessdate=July 15, 2017}}</ref>
|-
| 2013 || {{dts|January}} || Staff || Michael Anissimov leaves MIRI.<ref>{{cite web |url=https://intelligence.org/2013/03/07/march-newsletter/ |title=March Newsletter |publisher=Machine Intelligence Research Institute |date=March 7, 2013 |accessdate=July 1, 2017 |quote=Due to Singularity University's acquisition of the Singularity Summit and some major changes to MIRI's public communications strategy, Michael Anissimov left MIRI in January 2013. Michael continues to support our mission and continues to volunteer for us.}}</ref>
|-
| 2013 || {{dts|January 30}} || || MIRI announces that it has renamed itself from "Singularity Institute for Artificial Intelligence" to "Machine Intelligence Research Institute".<ref>{{cite web |url=https://intelligence.org/2013/01/30/we-are-now-the-machine-intelligence-research-institute-miri/ |title=We are now the "Machine Intelligence Research Institute" (MIRI) |publisher=Machine Intelligence Research Institute |date=January 30, 2013 |accessdate=June 30, 2017}}</ref>
|-
| 2013 || {{dts|February 1}} || Publication || ''Facing the Intelligence Explosion'' by Luke Muehlhauser is published by MIRI.<ref>{{cite web |url=https://www.amazon.com/facing-the-intelligence-explosion/dp/B00C7YOR5Q |title=Facing the Intelligence Explosion, Luke Muehlhauser |publisher=Amazon.com |accessdate=July 1, 2017 |quote=Publisher: Machine Intelligence Research Institute (February 1, 2013)}}</ref>
|-
| 2013 || {{dts|February 11}}{{snd}}{{dts|March 2}} || Domain || Sometime during this period, MIRI's new website at <code>intelligence.org</code> begins to function.<ref>{{cite web |url=https://web.archive.org/web/20130211105954/http://intelligence.org:80/ |title=Machine Intelligence Research Institute - Coming soon... |accessdate=July 4, 2017}}</ref><ref>{{cite web |url=https://web.archive.org/web/20130302063022/http://intelligence.org/ |title=Machine Intelligence Research Institute |accessdate=July 4, 2017}}</ref>
|-
| 2013 || {{dts|March 2}}{{snd}}{{dts|July 4}} || Domain || At least during this period, <code>singularity.org</code> redirects to <code>intelligence.org</code>, MIRI's new domain.<ref>{{cite web |url=https://web.archive.org/web/20130401000000*/singularity.org |title=Wayback Machine |accessdate=July 4, 2017}}</ref>
|-
| 2013 || {{dts|April 3}} || Publication || ''[[wikipedia:Singularity Hypotheses: A Scientific and Philosophical Assessment|Singularity Hypotheses: A Scientific and Philosophical Assessment]]'' is published by [[wikipedia:Springer Publishing|Springer]]. The book contains chapters written by MIRI researchers and research associates.<ref>{{cite web |url=https://intelligence.org/2013/04/25/singularity-hypotheses-published/ |title="Singularity Hypotheses" Published |publisher=Machine Intelligence Research Institute |author=Luke Muehlhauser |date=April 25, 2013 |accessdate=July 14, 2017}}</ref><ref>{{cite web |url=https://www.amazon.com/Singularity-Hypotheses-Scientific-Philosophical-Assessment/dp/3642325599/ |title=Singularity Hypotheses: A Scientific and Philosophical Assessment (The Frontiers Collection): 9783642325595: Medicine & Health Science Books |publisher=Amazon.com |accessdate=July 14, 2017 |quote=Publisher: Springer; 2012 edition (April 3, 2013)}}</ref>
|-
| 2013 || {{dts|April 3}}–24 || Workshop || The 2nd Workshop on Logic, Probability, and Reflection takes place.<ref name="workshops" />
|-
| 2013 || {{dts|April 13}} || Strategy || MIRI publishes an update on its strategy on its blog. In the blog post, MIRI executive director Luke Muehlhauser states that MIRI plans to put less effort into public outreach and shift its research to Friendly AI math research.<ref>{{cite web |url=https://intelligence.org/2013/04/13/miris-strategy-for-2013/ |title=MIRI's Strategy for 2013 |author=Luke Muehlhauser |publisher=Machine Intelligence Research Institute |date=December 11, 2013 |accessdate=July 6, 2017}}</ref>
|-
| 2013 || {{dts|July 4}} || Social media || MIRI's Twitter account, MIRIBerkeley, is created.<ref>{{cite web |url=https://twitter.com/MIRIBerkeley |title=MIRI (@MIRIBerkeley) |publisher=Twitter |accessdate=July 1, 2017}}</ref>
|-
| 2013 || {{dts|July 4}} || Social media || The earliest post on MIRI's Google Plus account, IntelligenceOrg, is from this day.<ref>{{cite web |url=https://plus.google.com/+IntelligenceOrg/posts/Ge3p8fPTkQn |title=MIRI's +Luke Muehlhauser appears on "Big Picture Science" at 13:30-23:30. |accessdate=July 4, 2017}}</ref><ref>{{cite web |url=https://plus.google.com/+IntelligenceOrg |title=Machine Intelligence Research Institute - Google+ |accessdate=July 4, 2017}}</ref>
|-
| 2013 || {{dts|July 8}}–14 || Workshop || The 3rd Workshop on Logic, Probability, and Reflection takes place.<ref name="workshops" />
|-
| 2013 || {{dts|August 4}} || Domain || By this point, <code>singularity.org</code> is operated by Singularity University.<ref>{{cite web |url=https://web.archive.org/web/20130804174727/http://www.singularity.org/ |title=Singularity Summit |accessdate=July 4, 2017}}</ref>
|-
| 2013 || {{dts|September 1}} || Publication || ''The Hanson-Yudkowsky AI-Foom Debate'' is published as an ebook by MIRI.<ref>{{cite web |url=https://www.amazon.com/dp/B00EZCFOG4/ |title=Amazon.com: The Hanson-Yudkowsky AI-Foom Debate eBook: Robin Hanson, Eliezer Yudkowsky: Kindle Store |accessdate=July 1, 2017 |quote=Publisher: Machine Intelligence Research Institute (September 1, 2013)}}</ref>
|-
| 2013 || {{dts|September 7}}–13 || Workshop || The 4th Workshop on Logic, Probability, and Reflection takes place.<ref name="workshops" />
|-
| 2013 || {{dts|October 25}} || Social media || The MIRI YouTube account, MIRIBerkeley, is created.<ref>{{cite web |url=https://www.youtube.com/user/MIRIBerkeley/about |title=Machine Intelligence Research Institute |publisher=YouTube |accessdate=July 4, 2017 |quote=Joined Oct 25, 2013}}</ref>
|-
| 2013 || {{dts|October 27}} || Outside review || MIRI meets with Holden Karnofsky, Jacob Steinhardt, and Dario Amodei for a discussion about MIRI's organizational strategy.<ref>{{cite web |url=https://intelligence.org/2014/01/13/miri-strategy-conversation-with-steinhardt-karnofsky-and-amodei/ |title=MIRI strategy conversation with Steinhardt, Karnofsky, and Amodei |publisher=Machine Intelligence Research Institute |author=Luke Muehlhauser |date=January 13, 2014 |accessdate=July 7, 2017}}</ref><ref name="open_phil_ai_risk_shallow">{{cite web |url=http://www.openphilanthropy.org/research/cause-reports/ai-risk |title=Potential Risks from Advanced Artificial Intelligence |publisher=Open Philanthropy Project |accessdate=July 7, 2017}}</ref>
|-
| 2013 || {{dts|November 23}}–29 || Workshop || The 5th Workshop on Logic, Probability, and Reflection takes place.<ref name="workshops" />
|-
| 2013 || {{dts|December 10}} || Domain || The first working Wayback Machine snapshot of the MIRI Volunteers website, available at <code>mirivolunteers.org</code>, is from this day.<ref>{{cite web |url=https://web.archive.org/web/20131210163948/http://mirivolunteers.org/ |title=Home - MIRI Volunteers |accessdate=July 14, 2017}}</ref>
|-
| 2013 || {{dts|December 14}}–20 || Workshop || The 6th Workshop on Logic, Probability, and Reflection takes place.<ref name="workshops" /> This is the first workshop attended by Nate Soares (at Google at the time), who would later becomes executive director of MIRI.<ref name="soares_taking_the_reins_at_miri" /><ref name="recent_hires_at_miri_mar_2014">{{cite web |url=https://intelligence.org/2014/03/13/hires/ |title=Recent Hires at MIRI |publisher=Machine Intelligence Research Institute |date=March 13, 2014 |accessdate=July 13, 2017}}</ref>
|-
| 2014 || {{dts|January}} (approximate) || Financial || [[wikipedia:Jed McCaleb|Jed McCaleb]], the creator of Ripple and original founder of [[wikipedia:Mt. Gox|Mt. Gox]], makes a donation worth $500,000 in XRP.<ref>{{cite web |url=http://www.coindesk.com/ripple-creator-500000-xrp-donation-ai-research-charity/ |date=January 19, 2014 |title=Ripple Creator Donates $500k in XRP to Artificial Intelligence Research Charity |author=Jon Southurst |publisher=CoinDesk |accessdate=July 6, 2017}}</ref>
|-
| 2014 || {{dts|January 16}} || Outside review || MIRI meets with Holden Karnofsky of GiveWell for a discussion on existential risk strategy.<ref>{{cite web |url=https://intelligence.org/2014/01/27/existential-risk-strategy-conversation-with-holden-karnofsky/ |title=Existential Risk Strategy Conversation with Holden Karnofsky |publisher=Machine Intelligence Research Institute |author=Luke Muehlhauser |date=January 27, 2014 |accessdate=July 7, 2017}}</ref><ref name="open_phil_ai_risk_shallow" />
|-
| 2014 || {{dts|February 1}} || Publication || ''Smarter Than Us: The Rise of Machine Intelligence'' by Stuart Armstrong is published by MIRI.<ref>{{cite web |url=https://www.amazon.com/Smarter-Than-Us-Machine-Intelligence-ebook/dp/B00IB4N4KU |title=Smarter Than Us: The Rise of Machine Intelligence, Stuart Armstrong |publisher=Amazon.com |accessdate=July 1, 2017 |quote=Publisher: Machine Intelligence Research Institute (February 1, 2014)}}</ref>
|-
| 2014 || {{dts|March}}–May || Influence || [[wikipedia:Future of Life Institute|Future of Life Institute]] (FLI) is founded.<ref>{{cite web |url=http://lesswrong.com/lw/kcm/new_organization_future_of_life_institute_fli/ |title=New organization - Future of Life Institute (FLI) |author=Victoria Krakovna |accessdate=July 6, 2017 |publisher=[[wikipedia:LessWrong|LessWrong]] |quote=As of May 2014, there is an existential risk research and outreach organization based in the Boston area. The Future of Life Institute (FLI), spearheaded by Max Tegmark, was co-founded by Jaan Tallinn, Meia Chita-Tegmark, Anthony Aguirre and myself.}}</ref> MIRI is a parter organization to FLI.<ref>{{cite web |url=https://futureoflife.org/news-from-our-partner-organizations/ |title=News from our Partner Organizations |publisher=Future of Life Institute |accessdate=July 6, 2017}}</ref> The Singularity Summit, MIRI's annual conference from 2006–2012, also played "a key causal role in getting [[wikipedia:Max Tegmark|Max Tegmark]] interested and the FLI created".<ref name="shulman_miri_causal_influences" /> "Tallinn, a co-founder of FLI and of the Cambridge Centre for the Study of Existential Risk (CSER), cites MIRI as a key source for his views on AI risk".<ref>{{cite web |url=https://intelligence.org/2015/08/10/assessing-our-past-and-potential-impact/ |title=Assessing our past and potential impact |publisher=Machine Intelligence Research Institute |author=Rob Bensinger |date=August 10, 2015 |accessdate=July 6, 2017}}</ref>
|-
| 2014 || {{dts|March 13}} || Staff || Some recent hires at MIRI are announced. Among the new team members is Nate Soares, who would become MIRI's executive director in 2015.<ref name="recent_hires_at_miri_mar_2014" />
|-
| 2014 || {{dts|May 3}}–11 || Workshop || The 7th Workshop on Logic, Probability, and Reflection takes place.<ref name="workshops" />
|-
| 2014 || {{dts|July}}–September || Influence || [[wikipedia:Nick Bostrom|Nick Bostrom]]'s book ''[[wikipedia:Superintelligence: Paths, Dangers, Strategies|Superintelligence: Paths, Dangers, Strategies]]'' is published. While Bostrom has never worked for MIRI, he is a research advisor to MIRI. MIRI also contributed substantially to the publication of the book.<ref name="shulman_miri_causal_influences">{{cite web |url=http://effective-altruism.com/ea/ns/my_cause_selection_michael_dickens/50b |title=Carl_Shulman comments on My Cause Selection: Michael Dickens |publisher=Effective Altruism Forum |accessdate=July 6, 2017 |date=September 17, 2015}}</ref>
|-
| 2014 || {{dts|July 4}} || Project || Earliest evidence of AI Impacts existing is from this day.<ref>{{cite web |url=https://web.archive.org/web/20141129001325/http://www.aiimpacts.org:80/system/app/pages/recentChanges |title=Recent site activity - AI Impacts |accessdate=June 30, 2017 |quote=Jul 4, 2014, 10:39 AM Katja Grace edited Predictions of human-level AI timelines}}</ref>
|-
| 2014 || {{dts|August}} || Project || The AI Impacts website launches.<ref>{{cite web |url=https://intelligence.org/2014/09/01/september-newsletter-2/ |title=MIRI's September Newsletter |publisher=Machine Intelligence Research Institute |date=September 1, 2014 |accessdate=July 15, 2017 |quote=Paul Christiano and Katja Grace have launched a new website containing many analyses related to the long-term future of AI: AI Impacts.}}</ref>
|-
| 2014 || {{dts|November 4}} || Project || The Intelligent Agent Foundations Forum, run by MIRI, is launched.<ref>{{cite web |url=https://agentfoundations.org/item?id=1 |website=Intelligent Agent Foundations Forum |title=Welcome! |author=Benja Fallenstein |accessdate=June 30, 2017 |quote=post by Benja Fallenstein 969 days ago}}</ref>
|-
| 2015 || {{dts|January}} || Project || AI Impacts rolls out a new website.<ref>{{cite web |url=https://intelligence.org/2015/01/11/improved-ai-impacts-website/ |title=An improved "AI Impacts" website |author=Luke Muehlhauser |publisher=Machine Intelligence Research Institute |date=January 11, 2015 |accessdate=June 30, 2017}}</ref>
|-
| 2015 || {{dts|January 2}}–5 || Conference || ''The Future of AI: Opportunities and Challenges'', an AI safety conference, takes place in Puerto Rico. The conference is organized by the Future of Life Institute, but several MIRI staff (including Luke Muehlhauser, Eliezer Yudkowsky, and Nate Soares) attend.<ref>{{cite web |url=https://futureoflife.org/2015/10/12/ai-safety-conference-in-puerto-rico/ |title=AI safety conference in Puerto Rico |publisher=Future of Life Institute |date=October 12, 2015 |accessdate=July 13, 2017}}</ref> Nate Soares would later call this the "turning point" of when top academics begin to focus on AI risk.<ref>{{cite web |url=https://intelligence.org/2015/07/16/an-astounding-year/ |title=An Astounding Year |publisher=Machine Intelligence Research Institute |author=Nate Soares |date=July 16, 2015 |accessdate=July 13, 2017}}</ref>
|-
| 2015 || {{dts|March 11}} || Influence || ''Rationality: From AI to Zombies'' is published. It is an ebook of Eliezer Yudkowsky's series of blog posts, called "the Sequences".<ref>{{cite web |url=http://lesswrong.com/lw/lvb/rationality_from_ai_to_zombies/ |title=Rationality: From AI to Zombies |date=March 13, 2015 |author=RobbBB |accessdate=July 1, 2017 |publisher=[[wikipedia:LessWrong|LessWrong]]}}</ref><ref>{{cite web |url=http://effective-altruism.com/ea/g6/rationality_from_ai_to_zombies_was_released_today/ |title=Rationality: From AI to Zombies was released today! |publisher=Effective Altruism Forum |author=Ryan Carey |accessdate=July 1, 2017}}</ref><ref>{{cite web |url=https://smile.amazon.com/Rationality-AI-Zombies-Eliezer-Yudkowsky-ebook/dp/B00ULP6EW2/ |title=Rationality: From AI to Zombies - Kindle edition by Eliezer Yudkowsky. Health, Fitness & Dieting Kindle eBooks @ Amazon.com. |accessdate=July 1, 2017 |quote=Publisher: Machine Intelligence Research Institute (March 11, 2015)}}</ref>
|-
| 2015 || {{dts|May 4}}–6 || Workshop || The 1st Introductory Workshop on Logical Decision Theory takes place.<ref name="workshops" />
|-
| 2015 || {{dts|May 6}} || Staff || Executive director Luke Muehlhauser announces his departure from MIRI. The announcement also states that Nate Soares will be the new executive director.<ref>{{cite web |url=https://intelligence.org/2015/05/06/a-fond-farewell-and-a-new-executive-director/ |title=A fond farewell and a new Executive Director |author=Luke Muehlhauser |publisher=Machine Intelligence Research Institute |date=May 6, 2015 |accessdate=June 30, 2017}}</ref>
|-
| 2015 || {{dts|May 29}}–31 || Workshop || The 1st Introductory Workshop on Logical Uncertainty takes place.<ref name="workshops" />
|-
| 2015 || {{dts|June 3}}–4 || Staff || Nate Soares begins as executive director of MIRI.<ref name="soares_taking_the_reins_at_miri">{{cite web |url=http://lesswrong.com/lw/ma4/taking_the_reins_at_miri/ |title=Taking the reins at MIRI |date=June 3, 2015 |accessdate=July 5, 2017 |publisher=[[wikipedia:LessWrong|LessWrong]]}}</ref>
|-
| 2015 || {{dts|June 11}} || || Nate Soares, executive director of MIRI, does an "ask me anything" (AMA) on the Effective Altruism Forum.<ref>{{cite web |url=http://effective-altruism.com/ea/ju/i_am_nate_soares_ama/ |title=I am Nate Soares, AMA! |publisher=Effective Altruism Forum |accessdate=July 5, 2017}}</ref>
|-
| 2015 || {{dts|June 12}}–14 || Workshop || The 2nd Introductory Workshop on Logical Decision Theory takes place.<ref name="workshops" />
|-
| 2015 || {{dts|June 26}}–28 || Workshop || The 1st Introductory Workshop on Vingean Reflection takes place.<ref name="workshops" />
|-
| 2015 || {{dts|July 7}}–26 || Project || The MIRI Summer Fellows program 2015, run by the Center for Applied Rationality, takes place.<ref>{{cite web |url=https://web.archive.org/web/20150717025843/http://rationality.org/miri-summer-fellows-2015 |title=MIRI Summer Fellows 2015 |publisher=CFAR |date=June 21, 2015 |accessdate=July 8, 2017}}</ref> This program is apparently "relatively successful at recruiting staff for MIRI".<ref>{{cite web |url=http://www.openphilanthropy.org/giving/grants/center-applied-rationality-general-support |title=Center for Applied Rationality — General Support |publisher=Open Philanthropy Project |accessdate=July 8, 2017 |quote=We have some doubts about CFAR's management and operations, and we see CFAR as having made only limited improvements over the last two years, with the possible exception of running the MIRI Summer Fellows Program in 2015, which we understand to have been relatively successful at recruiting staff for MIRI.}}</ref>
|-
| 2015 || {{dts|August 7}}–9 || Workshop || The 2nd Introductory Workshop on Logical Uncertainty takes place.<ref name="workshops" />
|-
| 2015 || {{dts|August 28}}–30 || Workshop || The 3rd Introductory Workshop on Logical Decision Theory takes place.<ref name="workshops" />
|-
| 2016 || || Publication || MIRI pays Eliezer Yudkowsky to produce AI risk content for Arbital.<ref>{{cite web |url=http://effective-altruism.com/ea/14w/2017_ai_risk_literature_review_and_charity/ |title=2017 AI Risk Literature Review and Charity Comparison |publisher=Effective Altruism Forum |author=Larks |date=December 13, 2016 |accessdate=July 8, 2017}}</ref> (Not sure if there are any more details of this available.)
|-
| 2016 || {{dts|April 1}}–3 || Workshop || The Self-Reference, Type Theory, and Formal Verification takes place.<ref name="workshops" />
|-
| 2016 || {{dts|May 28}}–29 || Workshop || The Colloquium Series on Robust and Beneficial AI (CSRBAI) Workshop on Transparency takes place.<ref name="workshops" />
|-
| 2016 || {{dts|June 4}}–5 || Workshop || The Colloquium Series on Robust and Beneficial AI (CSRBAI) Workshop on Robustness and Error-Tolerance takes place.<ref name="workshops" />
|-
| 2016 || {{dts|June 11}}–12 || Workshop || The Colloquium Series on Robust and Beneficial AI (CSRBAI) Workshop on Preference Specification takes place.<ref name="workshops" />
|-
| 2016 || {{dts|June 17}} || Workshop || The Colloquium Series on Robust and Beneficial AI (CSRBAI) Workshop on Agent Models and Multi-Agent Dilemmas takes place.<ref name="workshops" />
|-
| 2016 || {{dts|July 27}} || || MIRI announces its machine learning technical agenda, called "Alignment for Advanced Machine Learning Systems".<ref>{{cite web |url=https://intelligence.org/2016/07/27/alignment-machine-learning/ |title=New paper: "Alignment for advanced machine learning systems" |publisher=Machine Intelligence Research Institute |date=July 27, 2016 |author=Rob Bensinger |accessdate=July 1, 2017}}</ref>
|-
| 2016 || {{dts|August}} || Financial || The Open Philanthropy Project awards a grant worth $500,000 to Machine Intelligence Research Institute. The grant writeup notes, "Despite our strong reservations about the technical research we reviewed, we felt that awarding $500,000 was appropriate for multiple reasons".<ref>{{cite web |url=http://www.openphilanthropy.org/focus/global-catastrophic-risks/potential-risks-advanced-artificial-intelligence/machine-intelligence-research-institute-general-support |title=Machine Intelligence Research Institute — General Support |publisher=Open Philanthropy Project |accessdate=June 30, 2017}}</ref>
|-
| 2016 || {{dts|August 12}}–14 || Workshop || The 8th Workshop on Logic, Probability, and Reflection takes place.<ref name="workshops" />
|-
| 2016 || {{dts|August 26}}–28 || Workshop || The 1st Workshop on Machine Learning and AI Safety takes place.<ref name="workshops" />
|-
| 2016 || {{dts|September 12}} || Publication || MIRI announces the release of its new paper, "Logical Induction" by Scott Garrabrant, Tsvi Benson-Tilsen, Andrew Critch, Nate Soares, and Jessica Taylor.<ref>{{cite web |url=https://intelligence.org/2016/09/12/new-paper-logical-induction/ |title=New paper: "Logical induction" |publisher=Machine Intelligence Research Institute |date=March 23, 2017 |accessdate=July 1, 2017}}</ref><ref>{{cite web |url=http://www.scottaaronson.com/blog/?p=2918 |title=Shtetl-Optimized » Blog Archive » Stuff That's Happened |date=October 9, 2016 |author=Scott Aaronson |accessdate=July 1, 2017 |quote=Some of you will also have seen that folks from the Machine Intelligence Research Institute (MIRI)—Scott Garrabrant, Tsvi Benson-Tilsen, Andrew Critch, Nate Soares, and Jessica Taylor—recently put out a major 130-page paper entitled "Logical Induction".}}</ref>
|-
| 2016 || {{dts|October 12}} || || MIRI does an "ask me anything" (AMA) on the Effective Altruism Forum.<ref>{{cite web |url=http://effective-altruism.com/ea/12r/ask_miri_anything_ama/ |title=Ask MIRI Anything (AMA) |publisher=Effective Altruism Forum |date=October 11, 2016 |author=Rob Bensinger |accessdate=July 5, 2017}}</ref>
|-
| 2016 || {{dts|October 21}}–23 || Workshop || The 2nd Workshop on Machine Learning and AI Safety takes place.<ref name="workshops" />
|-
| 2016 || {{dts|November 11}}–13 || Workshop || The 9th Workshop on Logic, Probability, and Reflection takes place.<ref name="workshops" />
|-
| 2016 || {{dts|December}} || Financial || The Open Philanthropy Project awards a grant worth $32,000 to AI Impacts.<ref>{{cite web |url=http://www.openphilanthropy.org/focus/global-catastrophic-risks/potential-risks-advanced-artificial-intelligence/ai-impacts-general-support |title=AI Impacts — General Support |publisher=Open Philanthropy Project |accessdate=June 30, 2017}}</ref>
|-
| 2016 || {{dts|December 1}}–3 || Workshop || The 3rd Workshop on Machine Learning and AI Safety takes place.<ref name="workshops" />
|-
| 2017 || {{dts|March 25}}–26 || Workshop || The Workshop on Agent Foundations and AI Safety takes place.<ref name="workshops" />
|-
| 2017 || {{dts|April 1}}–2 || Workshop || The 4th Workshop on Machine Learning and AI Safety takes place.<ref name="workshops" />
|-
| 2017 || {{dts|May 24}} || Publication || "When Will AI Exceed Human Performance? Evidence from AI Experts" is published on the [[wikipedia:arXiv|arXiv]].<ref>{{cite web |url=https://arxiv.org/abs/1705.08807 |title=[1705.08807] When Will AI Exceed Human Performance? Evidence from AI Experts |accessdate=July 13, 2017}}</ref> Two researchers from AI Impacts are authors on the paper. The paper would be mentioned in more than twenty news articles.<ref>{{cite web |url=http://aiimpacts.org/media-discussion-of-2016-espai/ |title=Media discussion of 2016 ESPAI |publisher=AI Impacts |date=June 14, 2017 |accessdate=July 13, 2017}}</ref>
|-
| 2017 || {{dts|July 4}} || Strategy || MIRI announces that it will be putting relatively little work into the "Alignment for Advanced Machine Learning Systems" agenda over the next year due to the departure of Patrick LaVictoire and Jessica Taylor, and leave taken by Andrew Critch.<ref>{{cite web |url=https://intelligence.org/2017/07/04/updates-to-the-research-team-and-a-major-donation/ |title=Updates to the research team, and a major donation - Machine Intelligence Research Institute |publisher=Machine Intelligence Research Institute |date=July 4, 2017 |accessdate=July 4, 2017}}</ref>
|-
| 2017 || {{dts|July 7}} || Outside review || Daniel Dewey, program officer for potential risks from advanced artificial intelligence at the Open Philanthropy Project, publishes a post giving his thoughts on MIRI's work on highly reliable agent design. The post is intended to provide "an unambiguous snapshot" of Dewey's beliefs, and gives the case for highly reliable agent design work (as he understands it) and why he finds other approaches (such as learning to reason from humans) more promising.<ref>{{cite web |url=http://effective-altruism.com/ea/1ca/my_current_thoughts_on_miris_highly_reliable/ |title=My current thoughts on MIRI's "highly reliable agent design" work |author=Daniel Dewey |date=July 7, 2017 |publisher=Effective Altruism Forum |accessdate=July 7, 2017}}</ref>
|}

==Meta information on the timeline==

===How the timeline was built===

The initial version of the timeline was written by [[User:Issa|Issa Rice]].

Issa likes to work locally and track changes with Git, so the revision history on this wiki only shows changes in bulk. To see more incremental changes, refer to the [https://github.com/riceissa/issarice.com/commits/master/external/timelines.issarice.com/Timeline_of_Machine_Intelligence_Research_Institute.mediawiki commit history].

{{funding info}} is available.

===What the timeline is still missing===

* TODO Figure out how to cover publications
* TODO mention kurzweil
* TODO maybe include some of the largest donations (e.g. the XRP/ETH ones, tallinn, thiel)
* TODO maybe fundraisers
* TODO look more closely through some AMAs: [http://effective-altruism.com/ea/12r/ask_miri_anything_ama/], [http://effective-altruism.com/ea/ju/i_am_nate_soares_ama/]
* TODO maybe more info in this SSC post [http://slatestarcodex.com/2014/10/07/tumblr-on-miri/]
* TODO more links at EA Wikia page [http://effective-altruism.wikia.com/wiki/Library/Machine_Intelligence_Research_Institute]
* TODO lots of things from strategy updates, annual reviews, etc. [https://intelligence.org/2016/08/05/miri-strategy-update-2016/]
* TODO Ben Goertzel talks about his involvement with MIRI [https://multiverseaccordingtoben.blogspot.com/2010/10/singularity-institutes-scary-idea-and.html], also [https://web.archive.org/web/20100103192144/http://www.singinst.org:80/aboutus/ourhistory more on opencog]
* TODO giant thread on Ozy's blog [https://thingofthings.wordpress.com/2016/02/17/concerning-miris-place-in-the-ea-movement/]
* NOTE From 2017-07-06: "years that have few events so far: 2003 (one event), 2007 (one event), 2008 (three events), 2010 (three events), 2017 (three events)"
* TODO possibly include more from the [https://web.archive.org/web/20140517205902/http://mirivolunteers.org/ old MIRI volunteers site]. Some of the volunteering opportunities like proofreading and promoting MIRI by giving it good [https://web.archive.org/web/20140720043359/http://mirivolunteers.org/blog/ web of trust ratings] seem to give a good flavor of what MIRI was like, the specific challenges in terms of switching domains, and so on.
* TODO not sure how exactly to include this in the timeline, but something about MIRI's changing approach to funding certain types of contract work. e.g. Vipul [https://vipulnaik.com/miri/ says] "I believe the work I did with Luke would no longer be sponsored by MIRI as their research agenda is now much more narrowly focused on the mathematical parts."

===Timeline update strategy===

Some places to look on the MIRI blog:

* [https://intelligence.org/category/miri/ MIRI strategy posts]
* [https://intelligence.org/category/news/ News posts]
* [https://intelligence.org/category/newsletters/ Newsletters]

Also general stuff like big news coverage.

==See also==

* [[Timeline of Against Malaria Foundation]]
* [[Timeline of Center for Applied Rationality]]

==External links==

* [https://intelligence.org/ Official website]
* [https://agentfoundations.org/ Intelligent Agent Foundations Forum]
* [http://lesswrong.com/ LessWrong]
* [https://donations.vipulnaik.com/donee.php?donee=Machine+Intelligence+Research+Institute Donations information and other relevant documents], compiled by Vipul Naik

==References==

{{Reflist|30em}}
