This is a '''timeline of Berkeley Existential Risk Initiative'''.

==Big picture==

{| class="wikitable"
! Time period !! Development summary !! More details
|-
|}

==Full timeline==

{| class="sortable wikitable"
! Year !! Month and date !! Event type !! Details
|-
| 2017 || {{Dts|February 2}} || || On his blog, Andrew Critch publishes the post "Deserving Trust / Grokking Newcomb’s Problem", which explains his concept of "deserving trust" using Newcomb's problem.<ref>{{cite web |url=http://acritch.com/deserving-trust/ |title=Deserving Trust / Grokking Newcomb's Problem {{!}} Andrew Critch |accessdate=February 8, 2018}}</ref>
|-
| 2017 || {{Dts|April 20}} || || A post on the Effective Altruism Forum announces a grant from the Long-Term Future Fund (one of the EA Funds) to BERI worth $14,838.02.<ref>{{cite web |url=http://effective-altruism.com/ea/19d/update_on_effective_altruism_funds/ |title=Update on Effective Altruism Funds - Effective Altruism Forum |accessdate=February 8, 2018}}</ref>
|-
| 2017 || {{dts|May 20}} || || On his blog, Andrew Critch publishes the post "Deserving Trust, II: It’s not about reputation". The post gives a less mathematical explanation of what he means by "deserving trust". The post closes with: "I'm trying to do work that has some fairly broad-sweeping consequences, and I want to know, for myself, that we’re operating in a way that is deserving of the implicit trust of the societies and institutions that have already empowered us to have those consequences."<ref>{{cite web |url=http://acritch.com/deserving-trust-2/ |title=Deserving Trust, II: It's not about reputation {{!}} Andrew Critch |accessdate=February 8, 2018}}</ref>
|-
| 2017 || {{Dts|July}} || || BERI receives a grant of $403,890 from the Open Philanthropy Project to "support BERI core staff and collaboration between BERI and CHAI [the Center for Human-Compatible AI]".<ref>{{cite web |url=https://www.openphilanthropy.org/focus/global-catastrophic-risks/potential-risks-advanced-artificial-intelligence/berkeley-existential-risk-initiative-core-staff-and-chai-collaboration |publisher=Open Philanthropy Project |title=Berkeley Existential Risk Initiative (BERI) — Core Support and CHAI Collaboration |date=December 15, 2017 |accessdate=February 8, 2018}}</ref>
|-
| 2017 || {{dts|September 25}} || || BERI announces its first two grants: $100,000 each to the Machine Intelligence Research Institute and the Future of Life Institute.<ref>{{cite web |url=http://existence.org/grants |title=Berkeley Existential Risk Initiative {{!}} Announcing BERI's first grants program |accessdate=February 8, 2018}}</ref>
|-
| 2017 || {{dts|October 19}} || || Andrew Critch publishes a post on the BERI blog detailing BERI's thoughts on growth, ethics, and responsiveness. The section on ethics refers to two posts Critch wrote on his personal blog about deserving trust.<ref>{{cite web |url=http://existence.org/growth |title=Berkeley Existential Risk Initiative {{!}} What we're thinking about as we grow - ethics, oversight, and getting things done |accessdate=February 8, 2018}}</ref>
|-
| 2017 || {{dts|December}} || || BERI awards the Machine Intelligence Research Institute $100,000 during the latter's end-of-the-year fundraiser.<ref>{{cite web |url=https://intelligence.org/2018/01/10/fundraising-success/ |title=Fundraising success! - Machine Intelligence Research Institute |publisher=[[wikipedia:Machine Intelligence Research Institute|Machine Intelligence Research Institute]] |date=January 10, 2018 |accessdate=February 8, 2018}}</ref>
|}

==Meta information on the timeline==

===How the timeline was built===

The initial version of the timeline was written by [[User:Issa|Issa Rice]].

{{funding info}} is available.

===What the timeline is still missing===

===Timeline update strategy===

==See also==

==External links==

* [https://donations.vipulnaik.com/donee.php?donee=Berkeley+Existential+Risk+Initiative Donations List Website (donee)]
* [https://donations.vipulnaik.com/donor.php?donor=Berkeley+Existential+Risk+Initiative Donations List Website (donor)]
* [https://aiwatch.issarice.com/?organization=Berkeley+Existential+Risk+Initiative AI Watch]

==References==

{{Reflist|30em}}
