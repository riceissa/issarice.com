This is a '''timeline of Center for Human-Compatible AI'''.

==Big picture==

{| class="wikitable"
! Time period !! Development summary !! More details
|-
|}

==Full timeline==

{| class="sortable wikitable"
! Year !! Month and date !! Event type !! Details
|-
| 2016 || {{dts|August}} || Organization || The UC Berkeley Center for Human-Compatible Artificial Intelligence launches. The focus of the center is "to ensure that AI systems are beneficial to humans".<ref>{{cite web |url=http://news.berkeley.edu/2016/08/29/center-for-human-compatible-artificial-intelligence/ |title=UC Berkeley launches Center for Human-Compatible Artificial Intelligence |date=August 29, 2016 |publisher=Berkeley News |accessdate=July 26, 2017}}</ref>
|-
| 2016 || {{dts|August}} || Grant || The Open Philanthropy Project awards a grant of $5.6 million to the {{w|Center for Human-Compatible AI}}.<ref name="donations-portal-open-phil-ai-risk">{{cite web |url=https://donations.vipulnaik.com/donor.php?donor=Open+Philanthropy+Project&cause_area_filter=AI+risk |title=Open Philanthropy Project donations made (filtered to cause areas matching AI risk) |accessdate=July 27, 2017}}</ref>
|-
| 2016 || {{dts|November 24}} || || The initial version of "The Off-Switch Game", a paper by Dylan Hadfield-Menell, Anca Dragan, Pieter Abbeel, and Stuart Russell, is uploaded to the arXiv.<ref>{{cite web |url=https://arxiv.org/abs/1611.08219 |title=[1611.08219] The Off-Switch Game |accessdate=February 9, 2018}}</ref><ref name="2018_ai_safety_lit_review">{{cite web |url=http://effective-altruism.com/ea/1iu/2018_ai_safety_literature_review_and_charity/ |title=2018 AI Safety Literature Review and Charity Comparison - Effective Altruism Forum |accessdate=February 9, 2018}}</ref>
|-
| 2016 || {{dts|December}} || || CHAI's "Annotated bibliography of recommended materials" is published around this time.<ref>{{cite web |url=http://humancompatible.ai/bibliography |title=Center for Human-Compatible AI |accessdate=February 9, 2018}}</ref>
|-
| 2017 || {{dts|May 5}}–6 || || CHAI's first annual workshop takes place. The annual workshop is "designed to advance discussion and research" to "reorient the field of artificial intelligence toward developing systems that are provably beneficial to humans".<ref>{{cite web |url=http://humancompatible.ai/workshop-2017/ |title=Center for Human-Compatible AI |accessdate=February 9, 2018 |archiveurl=https://archive.is/pXQ4q |archivedate=February 9, 2018 |dead-url=no}}</ref>
|-
| 2017 || {{dts|May 28}} || || "Should Robots be Obedient?" by Smitha Milli, Dylan Hadfield-Menell, Anca Dragan, and Stuart Russell is uploaded to the arXiv.<ref>{{cite web |url=https://arxiv.org/abs/1705.09990 |title=[1705.09990] Should Robots be Obedient? |accessdate=February 9, 2018}}</ref><ref name="2018_ai_safety_lit_review" />
|-
| 2018 || {{dts|April 28}}–29 || || CHAI's second annual workshop is planned for these days.<ref>{{cite web |url=http://humancompatible.ai/workshop-2018 |title=Center for Human-Compatible AI |accessdate=February 9, 2018 |archiveurl=https://archive.is/XcxCZ |archivedate=February 9, 2018 |dead-url=no}}</ref>
|}

==Meta information on the timeline==

===How the timeline was built===

The initial version of the timeline was written by [[User:Issa|Issa Rice]].

{{funding info}} is available.

===What the timeline is still missing===

===Timeline update strategy===

==See also==

* [[Timeline of Machine Intelligence Research Institute]]
* [[Timeline of Future of Humanity Institute]]
* [[Timeline of OpenAI]]
* [[Timeline of Berkeley Existential Risk Initiative]]

==External links==

* [https://donations.vipulnaik.com/donee.php?donee=Center+for+Human-Compatible+AI Donations List Website (donee)]
* [https://aiwatch.issarice.com/?organization=Center+for+Human-Compatible+AI AI Watch]

==References==

{{Reflist|30em}}
