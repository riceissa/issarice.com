Comment to be made on https://www.greaterwrong.com/posts/HnC29723hm6kJT7KP/taking-ai-risk-seriously-thoughts-by-critch

> Even if you’re not interested in orienting your life around helping with x-risk – if you just want to not be *blindsided* by radical changes that may be coming,

> We don’t know exactly what will happen, but I expect serious changes of some sort over the next 10 years. Even if you aren’t committing to saving the world, I think it’s in your interest just to understand what is happening, so in a decade or two you aren’t completely lost.
>
> And even ‘understanding the situation’ is complicated enough that I think you need to be able to quit your day-job and focus full-time, in order to get oriented.

I was surprised by this, and would be curious to hear more about not-necessarily-altruistic people should be doing, or what altruistic people should be doing from a selfish perspective.

The only concrete suggestions I have seen so far were mentioned in the [80,000 Hours podcast episode with Paul Christiano](https://80000hours.org/podcast/episodes/paul-christiano-ai-alignment-solutions/), to save money (but how much?) and invest in certain companies (but which ones, and how much?).
